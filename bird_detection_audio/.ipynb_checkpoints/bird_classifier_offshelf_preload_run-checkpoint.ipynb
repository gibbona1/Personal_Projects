{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6db40fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16, VGG19, ResNet50\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import plotly\n",
    "import umap.umap_ as umap\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd7bf22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score, auc\n",
    "import plotly.figure_factory as ff\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from data_set_params import DataSetParams\n",
    "from scipy.io import wavfile\n",
    "params = DataSetParams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d278cd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " '.RData',\n",
       " '.Rhistory',\n",
       " '02032022_comparison_results',\n",
       " '06042022_comparison_results',\n",
       " '06042022_comparison_results2',\n",
       " '06042022_comparison_results3',\n",
       " '20220301_comparison_results',\n",
       " '20220302_comparison_results2',\n",
       " '20220303_comparison_results',\n",
       " '20220307_comparison_results',\n",
       " '20220310_comparison_results',\n",
       " '20220322_comparison_results',\n",
       " '20220407_comparison_results4',\n",
       " '20220420_comparison_results4',\n",
       " '20220509_comparison_results',\n",
       " '20220510_comparison_results',\n",
       " '20220510_comparison_results2',\n",
       " '20220524_comparison_results',\n",
       " '20220524_comparison_results2',\n",
       " '20220524_comparison_results3',\n",
       " '20220524_comparison_results4',\n",
       " '20220524_comparison_results5',\n",
       " '20220601_comparison_results',\n",
       " 'acoustic_indices.R',\n",
       " 'audio_15sec_split.ipynb',\n",
       " 'audio_download-Copy1.ipynb',\n",
       " 'audio_download.ipynb',\n",
       " 'audio_download_dun_laoghaire .ipynb',\n",
       " 'audio_feature_extraction-Copy1.ipynb',\n",
       " 'audio_feature_extraction.ipynb',\n",
       " 'best_model.data-00000-of-00001',\n",
       " 'best_model.index',\n",
       " 'birdnet_model',\n",
       " 'birdnet_tf.ipynb',\n",
       " 'bird_classifier.ipynb',\n",
       " 'bird_classifier_dl.ipynb',\n",
       " 'bird_classifier_dl_split.ipynb',\n",
       " 'bird_classifier_offshelf.ipynb',\n",
       " 'bird_classifier_offshelf_loop.ipynb',\n",
       " 'bird_classifier_offshelf_loop_concatenate.ipynb',\n",
       " 'bird_classifier_offshelf_mfcc.ipynb',\n",
       " 'bird_classifier_offshelf_preload_run.ipynb',\n",
       " 'bird_classifier_richfield.ipynb',\n",
       " 'bird_classifier_richfield_birdnet.ipynb',\n",
       " 'bird_classifier_richfield_concat.ipynb',\n",
       " 'bird_classifier_richfield_concat_loop.ipynb',\n",
       " 'bird_classifier_richfield_mult.ipynb',\n",
       " 'bird_classifier_richfield_mult_loop.ipynb',\n",
       " 'bird_classifier_shallow_net.ipynb',\n",
       " 'bird_classifier_vgg_precompute.ipynb',\n",
       " 'checkpoint',\n",
       " 'checkpoints',\n",
       " 'concat_run_10_per_choice.png',\n",
       " 'concat_run_5_per_choice.png',\n",
       " 'confusion_matrix',\n",
       " 'data_set_params.py',\n",
       " 'dublin_dl_birds_split',\n",
       " 'extract_run_info.R',\n",
       " 'extract_run_info_comparison.R',\n",
       " 'ff1010bird',\n",
       " 'ff1010bird_mfcc.npy',\n",
       " 'ff1010bird_mfcc_filenames.npy',\n",
       " 'ff1010bird_vgg.npy',\n",
       " 'ff1010bird_vgg_filenames.npy',\n",
       " 'filenames',\n",
       " 'kaleidoscope_results',\n",
       " 'loop_channel_accuracy.png',\n",
       " 'mfcc_0.jpeg',\n",
       " 'mfcc_1.jpeg',\n",
       " 'mfcc_10.jpeg',\n",
       " 'mfcc_11.jpeg',\n",
       " 'mfcc_12.jpeg',\n",
       " 'mfcc_13.jpeg',\n",
       " 'mfcc_14.jpeg',\n",
       " 'mfcc_15.jpeg',\n",
       " 'mfcc_16.jpeg',\n",
       " 'mfcc_17.jpeg',\n",
       " 'mfcc_18.jpeg',\n",
       " 'mfcc_19.jpeg',\n",
       " 'mfcc_2.jpeg',\n",
       " 'mfcc_3.jpeg',\n",
       " 'mfcc_4.jpeg',\n",
       " 'mfcc_5.jpeg',\n",
       " 'mfcc_6.jpeg',\n",
       " 'mfcc_7.jpeg',\n",
       " 'mfcc_8.jpeg',\n",
       " 'mfcc_9.jpeg',\n",
       " 'models',\n",
       " 'model_history',\n",
       " 'norfolk_small_cnn.h5',\n",
       " 'pred_df_softmax',\n",
       " 'results',\n",
       " 'richfield_bioacoustic_indices.csv',\n",
       " 'richfield_birds_split',\n",
       " 'richfield_birds_split_clean',\n",
       " 'richfield_mfcc.npy',\n",
       " 'richfield_test',\n",
       " 'richfield_vgg.npy',\n",
       " 'richfield_vgg1.npy',\n",
       " 'Rplot.png',\n",
       " 'Rplot01.png',\n",
       " 'Rplot02.png',\n",
       " 'Rplot03.png',\n",
       " 'Rplot04.png',\n",
       " 'Rplot05.png',\n",
       " 'Rplot06.png',\n",
       " 'Rplot07.png',\n",
       " 'Rplot08.png',\n",
       " 'Rplot09.png',\n",
       " 'Rplot10.png',\n",
       " 'SMU05115_Summary.txt',\n",
       " 'species list ireland - dun laoghaire.xlsx',\n",
       " 'species list richfield.xlsx',\n",
       " 'tf_helpers.py',\n",
       " 'warblrb10k_public',\n",
       " 'warblrb10k_public_mfcc.npy',\n",
       " 'warblrb10k_public_mfcc_filenames.npy',\n",
       " 'xc-tundra_swan_bewick-urls.txt',\n",
       " 'xeno_canto_files',\n",
       " 'y_pred',\n",
       " 'y_true',\n",
       " '_auth0.yml',\n",
       " '__pycache__']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9d372333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bird', 'not_bird']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data_dir = pathlib.Path('/root/tensorflow_datasets/downloads/extracted/TAR_GZ.opihi.cs.uvic.ca_sound_music_speechbya81rFcWfLSW6ey5cynqyeq2qiePcL-7asMoNO6IQ0.tar.gz/music_speech')\n",
    "#data_dir   = 'C:\\\\Users\\\\Anthony\\\\Downloads\\\\ff1010bird\\\\ff1010bird_wav\\\\wav'#\n",
    "#data_dir   = 'data/Richfield'#'dublin_dl_birds_split'#\n",
    "#data_dir   = 'richfield_birds_split'\n",
    "#data_dir = 'ff1010bird/ff1010bird_wav/wav'\n",
    "data_dir = 'warblrb10k_public/warblrb10k_public_wav/wav'\n",
    "categories = np.array(tf.io.gfile.listdir(data_dir))\n",
    "categories = [category for category in categories if 'wav' not in category and '.TAG' not in category]\n",
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "65a230e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(file_path):\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "\n",
    "    # Note: You'll use indexing here instead of tuple unpacking to enable this \n",
    "    # to work in a TensorFlow graph.\n",
    "    return parts[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "071ce280",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preload_vgg19(input_shape):\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=input_shape),\n",
    "        Flatten(), # Flatten dimensions to for use in FC layers\n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.5), # Dropout layer to reduce overfitting\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(num_classes, activation='softmax') # Softmax for multiclass\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer = optimizers.Adam(learning_rate=0.0001),\n",
    "        loss      = losses.SparseCategoricalCrossentropy(),\n",
    "        metrics   = 'accuracy'\n",
    "        )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a06054a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preload_vgg19_concat(input_shape, num_channels):\n",
    "    from tensorflow.keras.layers import concatenate\n",
    "    out_list   = []\n",
    "    input_list = []\n",
    "    for c in range(num_channels):\n",
    "        input_a = layers.Input(shape=input_shape)\n",
    "        input_list.append(input_a)\n",
    "        #out_list.append(vgg_model.output)\n",
    "    #vgg_model.summary()\n",
    "    #x = vgg_model.output\n",
    "    concatenated = concatenate(input_list, axis=-1)\n",
    "    x = Flatten()(concatenated) # Flatten dimensions to for use in FC layers\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x) # Dropout layer to reduce overfitting\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dense(num_classes, activation='softmax')(x) # Softmax for multiclass\n",
    "    concat_vgg_model = Model(inputs=input_list, outputs=x)\n",
    "    concat_vgg_model.compile(\n",
    "        optimizer = optimizers.Adam(learning_rate=0.0001),\n",
    "        loss      = losses.SparseCategoricalCrossentropy(),\n",
    "        metrics   = 'accuracy'\n",
    "        )\n",
    "    return concat_vgg_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1a79b82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preload_vgg19_mfcc(input_shape, mfcc_shape):\n",
    "    from tensorflow.keras.layers import concatenate\n",
    "    input_list = [layers.Input(shape=input_shape), layers.Input(shape=mfcc_shape)]\n",
    "    x = Flatten()(input_list[0]) # Flatten dimensions to for use in FC layers\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x) # Dropout layer to reduce overfitting\n",
    "    x1 = Flatten()(input_list[1])\n",
    "    concatenated = concatenate([x, x1], axis=-1)\n",
    "    x = Dense(64, activation='relu')(concatenated)\n",
    "    x = Dense(num_classes, activation='softmax')(x) # Softmax for multiclass\n",
    "    vgg_mfcc_model = Model(inputs=input_list, outputs=x)\n",
    "    vgg_mfcc_model.compile(\n",
    "        optimizer = optimizers.Adam(learning_rate=0.0001),\n",
    "        loss      = losses.SparseCategoricalCrossentropy(),\n",
    "        metrics   = 'accuracy'\n",
    "        )\n",
    "    return vgg_mfcc_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b62878f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preload_vgg19_mfcc_ind(input_shape, mfcc_shape, ind_shape):\n",
    "    from tensorflow.keras.layers import concatenate\n",
    "    input_list = [layers.Input(shape=input_shape), layers.Input(shape=mfcc_shape), layers.Input(shape=ind_shape)]\n",
    "    x = Flatten()(input_list[0]) # Flatten dimensions to for use in FC layers\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x) # Dropout layer to reduce overfitting\n",
    "    x1 = Flatten()(input_list[1])\n",
    "    x2 = Flatten()(input_list[2])\n",
    "    concatenated = concatenate([x, x1, x2], axis=-1)\n",
    "    x = Dense(64, activation='relu')(concatenated)\n",
    "    x = Dense(num_classes, activation='softmax')(x) # Softmax for multiclass\n",
    "    vgg_mfcc_model = Model(inputs=input_list, outputs=x)\n",
    "    vgg_mfcc_model.compile(\n",
    "        optimizer = optimizers.Adam(learning_rate=0.0001),\n",
    "        loss      = losses.SparseCategoricalCrossentropy(),\n",
    "        metrics   = 'accuracy'\n",
    "        )\n",
    "    return vgg_mfcc_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "489e0477",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = tf.io.gfile.glob(str(data_dir) + '/*/*')\n",
    "#filenames = tf.io.gfile.glob('birds/*/*')\n",
    "filenames = [filename for filename in filenames if 'wav' in filename]\n",
    "#filenames = tf.random.shuffle(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "42367d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE   = tf.data.experimental.AUTOTUNE\n",
    "batch_size = 32\n",
    "EPOCHS     = 20 #50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bd6c4b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "247c71d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3f2f66cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, roc_auc_score, top_k_accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from math import prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fd702f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a9b75f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(model, x_test, y_true, name, filename_run, index):\n",
    "        #model.save('models/'+filename_run+'.h5')\n",
    "    \n",
    "        pred_lists = model.predict(x_test)\n",
    "        y_pred     = np.argmax(pred_lists, axis=-1)\n",
    "        pred_df    = pd.DataFrame(pred_lists, columns = categories)\n",
    "        \n",
    "        softmax_prediction_df = pred_df.apply(lambda x: np.exp(x - np.max(x))/np.exp(x - np.max(x)).sum(), axis=1)\n",
    "        softmax_prediction_df.to_csv('results/'+filename_run+'_softmax_prediction_df.csv')\n",
    "        \n",
    "        #cm = confusion_matrix(y_true, y_pred)\n",
    "        #fig = plotly_cm(cm, categories)\n",
    "        #fig.write_html('results/'+filename_run+'_confusion_matrix.html')\n",
    "        \n",
    "        num_trainable    = sum([prod(w.shape) for w in model.trainable_weights])\n",
    "        num_nontrainable = sum([prod(w.shape) for w in model.non_trainable_weights])\n",
    "        \n",
    "        onehot_data = OneHotEncoder(sparse=False)\n",
    "        onehot_data = onehot_data.fit_transform(np.array(y_true).reshape(len(y_true),1))\n",
    "        roc_auc = [0]*num_classes\n",
    "        \n",
    "        for i in range(num_classes):\n",
    "            roc_auc[i] = roc_auc_score(onehot_data[:, i], softmax_prediction_df.to_numpy()[:, i])\n",
    "        \n",
    "        name_df = pd.DataFrame(data={\n",
    "                  'model':     name}, index=[index])\n",
    "        metric_df = pd.DataFrame(data={\n",
    "                  'top_1_acc': [accuracy_score(y_pred, y_true)],\n",
    "                  #'top_5_acc': [top_k_accuracy_score(y_true, softmax_prediction_df, k=5)],\n",
    "                  'precision': [precision_score(y_pred, y_true, average = 'weighted')], \n",
    "                  'f1':        [f1_score(y_pred, y_true, average = 'weighted')]\n",
    "                 })\n",
    "        param_df = pd.DataFrame(data={\n",
    "                  'trainable_params': [num_trainable],\n",
    "                  'nontrainable_params': [num_nontrainable]\n",
    "                 })\n",
    "        auc_df = pd.DataFrame([roc_auc], columns = ['auc_'+categories[i].replace(' ', '') for i in range(num_classes)])\n",
    "        \n",
    "        metric_df =  pd.concat([name_df, metric_df],axis=1)\n",
    "        metric_df.to_csv('results/'+filename_run+'_metric_df.csv')\n",
    "        \n",
    "        param_df  =  pd.concat([name_df, param_df],axis=1)\n",
    "        param_df.to_csv('results/'+filename_run+'_param_df.csv')\n",
    "        \n",
    "        auc_df    =  pd.concat([name_df, auc_df],axis=1)\n",
    "        auc_df.to_csv('results/'+filename_run+'_auc_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3795af9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vgg19(input_shape):\n",
    "    vgg_model = VGG19(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    vgg_model.trainable = False ## Not trainable weights\n",
    "    #vgg_model.summary()\n",
    "    x = vgg_model.output\n",
    "    x = Flatten()(x) # Flatten dimensions to for use in FC layers\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x) # Dropout layer to reduce overfitting\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dense(num_classes, activation='softmax')(x) # Softmax for multiclass\n",
    "    transfer_vgg_model = Model(inputs=vgg_model.input, outputs=x)\n",
    "    transfer_vgg_model.compile(\n",
    "        optimizer = optimizers.Adam(learning_rate=0.0001),\n",
    "        loss      = losses.SparseCategoricalCrossentropy(),\n",
    "        metrics   = 'accuracy'\n",
    "        )\n",
    "    return transfer_vgg_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982709cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "086337af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vgg19_concat(input_shape, num_channels):\n",
    "    from tensorflow.keras.layers import concatenate\n",
    "    out_list   = []\n",
    "    input_list = []\n",
    "    for c in range(num_channels):\n",
    "        vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "        vgg_model._name = vgg_model._name + str(c)\n",
    "        for layer in vgg_model.layers:\n",
    "            layer._name = layer._name + '_' + str(c)\n",
    "        vgg_model.trainable = False ## Not trainable weights\n",
    "        input_a = vgg_model.input\n",
    "        input_list.append(input_a)\n",
    "        out_list.append(vgg_model.output)\n",
    "    #vgg_model.summary()\n",
    "    #x = vgg_model.output\n",
    "    concatenated = concatenate(out_list)\n",
    "    x = Flatten()(concatenated) # Flatten dimensions to for use in FC layers\n",
    "    x = Dense(256*num_channels, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x) # Dropout layer to reduce overfitting\n",
    "    x = Dense(64*num_channels, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x) # Dropout layer to reduce overfitting\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dense(num_classes, activation='softmax')(x) # Softmax for multiclass\n",
    "    concat_vgg_model = Model(inputs=input_list, outputs=x)\n",
    "    concat_vgg_model.compile(\n",
    "        optimizer = optimizers.Adam(learning_rate=0.0001),\n",
    "        loss      = losses.SparseCategoricalCrossentropy(),\n",
    "        metrics   = 'accuracy'\n",
    "        )\n",
    "    return concat_vgg_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b5f530d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_resnet50(input_shape):\n",
    "    resnet_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    resnet_model.trainable = False ## Not trainable weights\n",
    "    #resnet_model.summary()\n",
    "    x = resnet_model.output\n",
    "    x = Flatten()(x) # Flatten dimensions to for use in FC layers\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x) # Dropout layer to reduce overfitting\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dense(num_classes, activation='softmax')(x) # Softmax for multiclass\n",
    "    transfer_resnet_model = Model(inputs=resnet_model.input, outputs=x)\n",
    "    transfer_resnet_model.compile(\n",
    "        optimizer = optimizers.Adam(learning_rate=0.0001),\n",
    "        loss      = losses.SparseCategoricalCrossentropy(),\n",
    "        metrics   = 'accuracy'\n",
    "        )\n",
    "    return transfer_resnet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f162967b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_resnet50_concat(input_shape, num_channels):\n",
    "    from tensorflow.keras.layers import concatenate\n",
    "    out_list   = []\n",
    "    input_list = []\n",
    "    for c in range(num_channels):\n",
    "        resnet_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "        resnet_model._name = resnet_model._name + str(c)\n",
    "        for layer in resnet_model.layers:\n",
    "            layer._name = layer._name + '_' + str(c)\n",
    "        resnet_model.trainable = False ## Not trainable weights\n",
    "        input_a = resnet_model.input\n",
    "        input_list.append(input_a)\n",
    "        out_list.append(resnet_model.output)\n",
    "    #vgg_model.summary()\n",
    "    #x = vgg_model.output\n",
    "    concatenated = concatenate(out_list)\n",
    "    x = Flatten()(concatenated) # Flatten dimensions to for use in FC layers\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x) # Dropout layer to reduce overfitting\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dense(num_classes, activation='softmax')(x) # Softmax for multiclass\n",
    "    concat_resnet_model = Model(inputs=input_list, outputs=x)\n",
    "    concat_resnet_model.compile(\n",
    "        optimizer = optimizers.Adam(learning_rate=0.0001),\n",
    "        loss      = losses.SparseCategoricalCrossentropy(),\n",
    "        metrics   = 'accuracy'\n",
    "        )\n",
    "    return concat_resnet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0c3aa315",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labs    = [get_label(y).numpy().decode() for y in filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "70d92a2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " 'not_bird',\n",
       " ...]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_labs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9ce69b",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cec79371",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = data_dir.split('/')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c22fc4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_X     = np.load(fname+'_spec1.npy')\n",
    "vgg_X     = np.load(fname+'_vgg1.npy')\n",
    "y_labs    = np.array([categories.index(y) for y in all_labs])\n",
    "mfcc_X    = np.load(fname+'_mfcc.npy')\n",
    "#indices_df = pd.read_csv(fname+'_bioacoustic_indices.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "816f0d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get VGG input data\n"
     ]
    }
   ],
   "source": [
    "#choices  = ['Mod']\n",
    "#main_ds = preprocess_dataset(filenames, choices, categories, req_width=750, resize = 4, spec_norm = True)\n",
    "\n",
    "#main_ds_vgg = preprocess_dataset(filenames, choices, categories, req_width=750, single_to_rgb = True, resize = 4, spec_norm = True)\n",
    "#print(\"Get VGG input data\")\n",
    "#X = np.array([x for x,y in main_ds_vgg])\n",
    "#y = np.array([y for _,y in train_ds_vgg])\n",
    "\n",
    "#for spec, _ in train_ds.take(1):\n",
    "#    input_shape = spec.shape\n",
    "#print(\"Get VGG precomputed data\")\n",
    "#for spec, _ in main_ds_vgg.take(1):\n",
    "#    input_shape_vgg = spec.shape\n",
    "#vgg_model = VGG19(weights='imagenet', include_top=False, input_shape=input_shape_vgg)\n",
    "#vgg_X = vgg_model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "af4a05e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save('richfield_vgg1.npy', vgg_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7fa090e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_df['name'] = ['\\\\'.join(str(y).split('/')[-3:]) for y in indices_df['name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5e327586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2840"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(indices_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "82e1008e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2840"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filenames - indices_df['name'].tolist()\n",
    "len(set(indices_df['name'].tolist()))\n",
    "#type(filenames)\n",
    "#type(indices_df['name'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "eb1d76b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2840"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0eb412da",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_df = pd.DataFrame({'name': filenames})\n",
    "tmp_df = pd.merge(file_df, indices_df, on = 'name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cfef54aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>aci</th>\n",
       "      <th>h</th>\n",
       "      <th>m</th>\n",
       "      <th>ndsi</th>\n",
       "      <th>q</th>\n",
       "      <th>adi</th>\n",
       "      <th>aei</th>\n",
       "      <th>bi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>richfield_birds_split\\European Herring Gull\\xc...</td>\n",
       "      <td>x724</td>\n",
       "      <td>162.508567</td>\n",
       "      <td>0.521850</td>\n",
       "      <td>0.009152</td>\n",
       "      <td>-0.996581</td>\n",
       "      <td>3.387936</td>\n",
       "      <td>0.896110</td>\n",
       "      <td>0.798566</td>\n",
       "      <td>3.851220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>richfield_birds_split\\European Herring Gull\\xc...</td>\n",
       "      <td>x725</td>\n",
       "      <td>173.748638</td>\n",
       "      <td>0.660751</td>\n",
       "      <td>0.019472</td>\n",
       "      <td>0.197235</td>\n",
       "      <td>7.528388</td>\n",
       "      <td>1.382985</td>\n",
       "      <td>0.675249</td>\n",
       "      <td>9.108642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>richfield_birds_split\\European Herring Gull\\xc...</td>\n",
       "      <td>x726</td>\n",
       "      <td>184.727582</td>\n",
       "      <td>0.654157</td>\n",
       "      <td>0.009242</td>\n",
       "      <td>-0.528473</td>\n",
       "      <td>5.418793</td>\n",
       "      <td>1.587540</td>\n",
       "      <td>0.615662</td>\n",
       "      <td>12.197591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>richfield_birds_split\\European Herring Gull\\xc...</td>\n",
       "      <td>x729</td>\n",
       "      <td>218.397686</td>\n",
       "      <td>0.787124</td>\n",
       "      <td>0.006227</td>\n",
       "      <td>-0.117635</td>\n",
       "      <td>32.249289</td>\n",
       "      <td>1.340695</td>\n",
       "      <td>0.636550</td>\n",
       "      <td>284.040826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>richfield_birds_split\\European Herring Gull\\xc...</td>\n",
       "      <td>x730</td>\n",
       "      <td>184.378684</td>\n",
       "      <td>0.784450</td>\n",
       "      <td>0.005943</td>\n",
       "      <td>-0.615434</td>\n",
       "      <td>1.529246</td>\n",
       "      <td>1.175008</td>\n",
       "      <td>0.686103</td>\n",
       "      <td>239.246663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2835</th>\n",
       "      <td>richfield_birds_split\\Tundra Swan\\xc72963_left...</td>\n",
       "      <td>x2227</td>\n",
       "      <td>161.815132</td>\n",
       "      <td>0.710443</td>\n",
       "      <td>0.006664</td>\n",
       "      <td>-0.495737</td>\n",
       "      <td>3.767874</td>\n",
       "      <td>1.399870</td>\n",
       "      <td>0.678685</td>\n",
       "      <td>5.139613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2836</th>\n",
       "      <td>richfield_birds_split\\Tundra Swan\\xc72963_left...</td>\n",
       "      <td>x2228</td>\n",
       "      <td>161.114332</td>\n",
       "      <td>0.733268</td>\n",
       "      <td>0.005713</td>\n",
       "      <td>-0.479589</td>\n",
       "      <td>1.812479</td>\n",
       "      <td>1.783743</td>\n",
       "      <td>0.545330</td>\n",
       "      <td>5.000558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2837</th>\n",
       "      <td>richfield_birds_split\\Tundra Swan\\xc92087_star...</td>\n",
       "      <td>x2229</td>\n",
       "      <td>185.537656</td>\n",
       "      <td>0.696037</td>\n",
       "      <td>0.021845</td>\n",
       "      <td>-0.250548</td>\n",
       "      <td>5.921843</td>\n",
       "      <td>1.401927</td>\n",
       "      <td>0.686034</td>\n",
       "      <td>11.689774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2838</th>\n",
       "      <td>richfield_birds_split\\Tundra Swan\\xc92087_star...</td>\n",
       "      <td>x2230</td>\n",
       "      <td>187.859630</td>\n",
       "      <td>0.692561</td>\n",
       "      <td>0.022229</td>\n",
       "      <td>-0.439318</td>\n",
       "      <td>0.619334</td>\n",
       "      <td>1.266071</td>\n",
       "      <td>0.726102</td>\n",
       "      <td>10.474556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2839</th>\n",
       "      <td>richfield_birds_split\\Tundra Swan\\xc92087_star...</td>\n",
       "      <td>x2231</td>\n",
       "      <td>181.865085</td>\n",
       "      <td>0.681315</td>\n",
       "      <td>0.024758</td>\n",
       "      <td>-0.483872</td>\n",
       "      <td>2.843790</td>\n",
       "      <td>1.322663</td>\n",
       "      <td>0.705098</td>\n",
       "      <td>10.209152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2840 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   name Unnamed: 0  \\\n",
       "0     richfield_birds_split\\European Herring Gull\\xc...       x724   \n",
       "1     richfield_birds_split\\European Herring Gull\\xc...       x725   \n",
       "2     richfield_birds_split\\European Herring Gull\\xc...       x726   \n",
       "3     richfield_birds_split\\European Herring Gull\\xc...       x729   \n",
       "4     richfield_birds_split\\European Herring Gull\\xc...       x730   \n",
       "...                                                 ...        ...   \n",
       "2835  richfield_birds_split\\Tundra Swan\\xc72963_left...      x2227   \n",
       "2836  richfield_birds_split\\Tundra Swan\\xc72963_left...      x2228   \n",
       "2837  richfield_birds_split\\Tundra Swan\\xc92087_star...      x2229   \n",
       "2838  richfield_birds_split\\Tundra Swan\\xc92087_star...      x2230   \n",
       "2839  richfield_birds_split\\Tundra Swan\\xc92087_star...      x2231   \n",
       "\n",
       "             aci         h         m      ndsi          q       adi       aei  \\\n",
       "0     162.508567  0.521850  0.009152 -0.996581   3.387936  0.896110  0.798566   \n",
       "1     173.748638  0.660751  0.019472  0.197235   7.528388  1.382985  0.675249   \n",
       "2     184.727582  0.654157  0.009242 -0.528473   5.418793  1.587540  0.615662   \n",
       "3     218.397686  0.787124  0.006227 -0.117635  32.249289  1.340695  0.636550   \n",
       "4     184.378684  0.784450  0.005943 -0.615434   1.529246  1.175008  0.686103   \n",
       "...          ...       ...       ...       ...        ...       ...       ...   \n",
       "2835  161.815132  0.710443  0.006664 -0.495737   3.767874  1.399870  0.678685   \n",
       "2836  161.114332  0.733268  0.005713 -0.479589   1.812479  1.783743  0.545330   \n",
       "2837  185.537656  0.696037  0.021845 -0.250548   5.921843  1.401927  0.686034   \n",
       "2838  187.859630  0.692561  0.022229 -0.439318   0.619334  1.266071  0.726102   \n",
       "2839  181.865085  0.681315  0.024758 -0.483872   2.843790  1.322663  0.705098   \n",
       "\n",
       "              bi  \n",
       "0       3.851220  \n",
       "1       9.108642  \n",
       "2      12.197591  \n",
       "3     284.040826  \n",
       "4     239.246663  \n",
       "...          ...  \n",
       "2835    5.139613  \n",
       "2836    5.000558  \n",
       "2837   11.689774  \n",
       "2838   10.474556  \n",
       "2839   10.209152  \n",
       "\n",
       "[2840 rows x 10 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_df#[tmp_df['label']=='Common Snipe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2f8bfa72",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in tmp_df.columns[2:]:\n",
    "    tmp_df[tmp_df[c].isna()] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a826270e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>aci</th>\n",
       "      <th>h</th>\n",
       "      <th>m</th>\n",
       "      <th>ndsi</th>\n",
       "      <th>q</th>\n",
       "      <th>adi</th>\n",
       "      <th>aei</th>\n",
       "      <th>bi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [name, Unnamed: 0, aci, h, m, ndsi, q, adi, aei, bi]\n",
       "Index: []"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_df[tmp_df['q'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "edd3d328",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "x = tmp_df.iloc[:,2:].values #returns a numpy array\n",
    "min_max_scaler = MinMaxScaler()\n",
    "indices_X = min_max_scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9d6b779b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.59460954, 0.54062313, 0.04661198, ..., 0.38917666, 0.89136911,\n",
       "        0.01355868],\n",
       "       [0.63573632, 0.68452197, 0.09916977, ..., 0.60062434, 0.75372117,\n",
       "        0.03206807],\n",
       "       [0.67590765, 0.67769016, 0.04706792, ..., 0.68946169, 0.68720944,\n",
       "        0.04294309],\n",
       "       ...,\n",
       "       [0.67887166, 0.72107696, 0.11125499, ..., 0.60885077, 0.76575952,\n",
       "        0.04115526],\n",
       "       [0.68736763, 0.7174758 , 0.11321316, ..., 0.5498491 , 0.81048391,\n",
       "        0.03687694],\n",
       "       [0.66543393, 0.70582552, 0.12608897, ..., 0.57442676, 0.78703899,\n",
       "        0.03594255]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "50413384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2840, 8)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e0524ef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2840, 4, 23, 512), (2840,), (2840, 30, 39), (2840, 8))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_X.shape, y_labs.shape, mfcc_X.shape, indices_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1e68a06e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 30, 39, 1)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.expand_dims(mfcc_X, axis=-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0d5fa340",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_model_run_loaded(filenames, index,\n",
    "                          X, y_labs,\n",
    "                          vgg_X,\n",
    "                          mfcc_X,\n",
    "                          ind_X,\n",
    "                          small_cnn = True,\n",
    "                          mfcc_cnn = True,\n",
    "                          vgg19    = True,\n",
    "                          vgg_mfcc = True,\n",
    "                          vgg_ind  = True,\n",
    "                          vgg_mfcc_ind = True):\n",
    "    print(\"Index: \", index)\n",
    "    \n",
    "    #concat_shape     = X_train_mult[0].shape[1:]\n",
    "    #vgg_concat_shape = X_train_mult_vgg[0].shape[1:]\n",
    "    \n",
    "    #input_shape_vgg  = vgg_X.shape[1:]\n",
    "    #input_shape_mfcc = mfcc_X.shape[1:]\n",
    "    #input_shape_ind  = indices_X.shape[1:]\n",
    "    \n",
    "    filename_df = pd.DataFrame({'name': filenames,\n",
    "                                'label': y_labs})\n",
    "    train, rest_df = train_test_split(filename_df, test_size=0.2, stratify=filename_df[['label']])\n",
    "    val, test      = train_test_split(rest_df, test_size=0.5, stratify = rest_df[['label']])\n",
    "    \n",
    "    if data_dir.startswith(\"C:\"):\n",
    "        sv_dir = '_'.join(data_dir.split(os.path.sep)[1:-2])\n",
    "    else:\n",
    "        sv_dir = data_dir\n",
    "    filename_idx = datetime.now().strftime(\"%Y%m%d-%H%M%S\").replace('-', '_')+'_'+sv_dir.replace('/','_')+'_'+str(index)\n",
    "    results_folder = 'results'\n",
    "    if not os.path.isdir(results_folder):\n",
    "        os.mkdir(results_folder)\n",
    "    \n",
    "    train.to_csv(results_folder+'/'+filename_idx+'_filenames_train.csv')\n",
    "    val.to_csv(results_folder+'/'+filename_idx+'_filenames_val.csv')\n",
    "    test.to_csv(results_folder+'/'+filename_idx+'_filenames_test.csv')\n",
    "    #np.save('results/'+filename_idx+'_filenames.npy', filenames.numpy())\n",
    "    mfcc_X = np.expand_dims(mfcc_X, axis=-1)\n",
    "    \n",
    "    y_train, y_val, y_test = y_labs[train.index], y_labs[val.index], y_labs[test.index]\n",
    "    X_train, X_val, X_test = X[train.index], X[val.index], X[test.index]\n",
    "    vgg_X_train,  vgg_X_val,  vgg_X_test  = vgg_X[train.index], vgg_X[val.index], vgg_X[test.index]\n",
    "    mfcc_X_train, mfcc_X_val, mfcc_X_test = mfcc_X[train.index], mfcc_X[val.index], mfcc_X[test.index]\n",
    "    #ind_X_train,  ind_X_val,  ind_X_test  = np.array(ind_X_train),  np.array(ind_X_val),  np.array(ind_X_test)\n",
    "    #this will save the model performing best on val accuracy\n",
    "    def best_model_cp():\n",
    "        checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "            \"best_model\",\n",
    "            monitor = \"val_accuracy\",\n",
    "            mode    = \"max\",\n",
    "            save_best_only = True,\n",
    "            save_weights_only = True)\n",
    "        return checkpoint\n",
    "    \n",
    "    ## Load and run models\n",
    "    if small_cnn:\n",
    "        print(\"Small CNN\")\n",
    "        model = main_cnn(X_train.shape[1:], num_classes)\n",
    "        model_name   = 'small_cnn'\n",
    "        filename_run = filename_idx+'_'+model_name\n",
    "        print(model.summary())\n",
    "        history = model.fit(X_train, y_train,\n",
    "                            validation_data = (X_val, y_val),\n",
    "                            callbacks       = [best_model_cp()],\n",
    "                            epochs          = EPOCHS,\n",
    "                            verbose         = 1)\n",
    "\n",
    "        pd.DataFrame(history.history).to_csv(results_folder+'/'+filename_run+'_model_history.csv')\n",
    "\n",
    "        model.load_weights(\"best_model\")\n",
    "\n",
    "        save_results(model, X_test, y_test, model_name, filename_run, index)\n",
    "    \n",
    "    if mfcc_cnn:\n",
    "        print(\"MFCC CNN\")\n",
    "        model = main_cnn(mfcc_X_train.shape[1:], num_classes)\n",
    "        model_name   = 'mfcc_cnn'\n",
    "        filename_run = filename_idx+'_'+model_name\n",
    "        print(model.summary())\n",
    "        history = model.fit(mfcc_X_train, y_train,\n",
    "                            validation_data = (mfcc_X_val, y_val),\n",
    "                            callbacks       = [best_model_cp()],\n",
    "                            epochs          = EPOCHS,\n",
    "                            verbose         = 1)\n",
    "\n",
    "        pd.DataFrame(history.history).to_csv(results_folder+'/'+filename_run+'_model_history.csv')\n",
    "\n",
    "        model.load_weights(\"best_model\")\n",
    "\n",
    "        save_results(model, mfcc_X_test, y_test, model_name, filename_run, index)\n",
    "    \n",
    "    #VGG19\n",
    "    if vgg19:\n",
    "        print(\"VGG19\")\n",
    "        model = preload_vgg19(vgg_X_train.shape[1:])\n",
    "        model_name   = 'vgg19'\n",
    "        filename_run = filename_idx+'_'+model_name\n",
    "        print(model.summary())\n",
    "        history = model.fit(vgg_X_train, y_train,\n",
    "                            validation_data = (vgg_X_val, y_val),\n",
    "                            callbacks       = [best_model_cp()],\n",
    "                            epochs          = EPOCHS,\n",
    "                            verbose         = 1)\n",
    "\n",
    "        pd.DataFrame(history.history).to_csv(results_folder+'/'+filename_run+'_model_history.csv')\n",
    "\n",
    "        model.load_weights(\"best_model\")\n",
    "\n",
    "        save_results(model, vgg_X_test, y_test, model_name, filename_run, index)\n",
    "    \n",
    "    \n",
    "   #VGG with MFCC components     \n",
    "    if vgg_mfcc:\n",
    "        print(\"VGG MFCC\")\n",
    "        \n",
    "        model        = preload_vgg19_mfcc(vgg_X_train.shape[1:], mfcc_X_train.shape[1:])\n",
    "        #model        = concat_model4(concat_shape, num_channels, num_classes)\n",
    "        model_name   = 'vgg_mfcc'\n",
    "        filename_run = filename_idx+'_'+model_name\n",
    "\n",
    "        history = model.fit([vgg_X_train, mfcc_X_train], y_train,\n",
    "                            validation_data = ([vgg_X_val, mfcc_X_val], y_val),\n",
    "                            callbacks       = [best_model_cp()],\n",
    "                            epochs          = EPOCHS,\n",
    "                            batch_size      = batch_size,\n",
    "                            verbose         = 1)\n",
    "\n",
    "        pd.DataFrame(history.history).to_csv(results_folder+'/'+filename_run+'_model_history.csv')\n",
    "\n",
    "        model.load_weights(\"best_model\")\n",
    "\n",
    "        save_results(model, [vgg_X_test, mfcc_X_test], y_test, model_name, filename_run, index)\n",
    "        \n",
    "    if vgg_ind:\n",
    "        print(\"VGG Bioacoustic Indices\")\n",
    "        ind_X_train,  ind_X_val,  ind_X_test  = ind_X[train.index], ind_X[val.index], ind_X[test.index]\n",
    "    \n",
    "        model        = preload_vgg19_mfcc(vgg_X_train.shape[1:], ind_X_train.shape[1:])\n",
    "        #model        = concat_model4(concat_shape, num_channels, num_classes)\n",
    "        model_name   = 'vgg_ind'\n",
    "        filename_run = filename_idx+'_'+model_name\n",
    "\n",
    "        history = model.fit([vgg_X_train, ind_X_train], y_train,\n",
    "                            validation_data = ([vgg_X_val, ind_X_val], y_val),\n",
    "                            callbacks       = [best_model_cp()],\n",
    "                            epochs          = EPOCHS,\n",
    "                            batch_size      = batch_size,\n",
    "                            verbose         = 1)\n",
    "\n",
    "        pd.DataFrame(history.history).to_csv(results_folder+'/'+filename_run+'_model_history.csv')\n",
    "\n",
    "        model.load_weights(\"best_model\")\n",
    "\n",
    "        save_results(model, [vgg_X_test, ind_X_test], y_test, model_name, filename_run, index)\n",
    "        \n",
    "    if vgg_mfcc_ind:\n",
    "        print(\"VGG, MFCC and Bioacoustic Indices\")\n",
    "        \n",
    "        model        = preload_vgg19_mfcc_ind(vgg_X_train.shape[1:], mfcc_X_train.shape[1:], ind_X_train.shape[1:])\n",
    "        #model        = concat_model4(concat_shape, num_channels, num_classes)\n",
    "        model_name   = 'vgg_mfcc_ind'\n",
    "        filename_run = filename_idx+'_'+model_name\n",
    "\n",
    "        history = model.fit([vgg_X_train, mfcc_X_train, ind_X_train], y_train,\n",
    "                            validation_data = ([vgg_X_val, mfcc_X_val, ind_X_val], y_val),\n",
    "                            callbacks       = [best_model_cp()],\n",
    "                            epochs          = EPOCHS,\n",
    "                            batch_size      = batch_size,\n",
    "                            verbose         = 1)\n",
    "\n",
    "        pd.DataFrame(history.history).to_csv(results_folder+'/'+filename_run+'_model_history.csv')\n",
    "\n",
    "        model.load_weights(\"best_model\")\n",
    "\n",
    "        save_results(model, [vgg_X_test, mfcc_X_test, ind_X_test], y_test, model_name, filename_run, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b1524e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092e1edd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4d1f5137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:  4\n",
      "Small CNN\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_27 (Conv2D)           (None, 126, 123, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 63, 61, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 61, 59, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 30, 29, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 28, 27, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 14, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_22 (Flatten)         (None, 5824)              0         \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 5824)              0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 64)                372800    \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 380,338\n",
      "Trainable params: 380,338\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 0.7332 - accuracy: 0.7330 - val_loss: 0.5590 - val_accuracy: 0.7887\n",
      "Epoch 2/20\n",
      "200/200 [==============================] - 29s 146ms/step - loss: 0.5702 - accuracy: 0.7859 - val_loss: 0.5340 - val_accuracy: 0.8037\n",
      "Epoch 3/20\n",
      "200/200 [==============================] - 31s 155ms/step - loss: 0.5432 - accuracy: 0.7950 - val_loss: 0.5224 - val_accuracy: 0.8075\n",
      "Epoch 4/20\n",
      "200/200 [==============================] - 31s 153ms/step - loss: 0.5182 - accuracy: 0.8037 - val_loss: 0.5139 - val_accuracy: 0.8025\n",
      "Epoch 5/20\n",
      "200/200 [==============================] - 29s 143ms/step - loss: 0.5038 - accuracy: 0.8072 - val_loss: 0.5061 - val_accuracy: 0.8175\n",
      "Epoch 6/20\n",
      "200/200 [==============================] - 28s 142ms/step - loss: 0.4896 - accuracy: 0.8109 - val_loss: 0.4925 - val_accuracy: 0.8125\n",
      "Epoch 7/20\n",
      "200/200 [==============================] - 28s 142ms/step - loss: 0.4726 - accuracy: 0.8197 - val_loss: 0.4856 - val_accuracy: 0.8225\n",
      "Epoch 8/20\n",
      "200/200 [==============================] - 28s 141ms/step - loss: 0.4570 - accuracy: 0.8255 - val_loss: 0.4758 - val_accuracy: 0.8250\n",
      "Epoch 9/20\n",
      "200/200 [==============================] - 29s 143ms/step - loss: 0.4461 - accuracy: 0.8289 - val_loss: 0.4732 - val_accuracy: 0.8225\n",
      "Epoch 10/20\n",
      "200/200 [==============================] - 29s 143ms/step - loss: 0.4411 - accuracy: 0.8316 - val_loss: 0.4700 - val_accuracy: 0.8313\n",
      "Epoch 11/20\n",
      "200/200 [==============================] - 28s 141ms/step - loss: 0.4288 - accuracy: 0.8311 - val_loss: 0.4650 - val_accuracy: 0.8275\n",
      "Epoch 12/20\n",
      "200/200 [==============================] - 28s 142ms/step - loss: 0.4257 - accuracy: 0.8403 - val_loss: 0.4600 - val_accuracy: 0.8338\n",
      "Epoch 13/20\n",
      "200/200 [==============================] - 29s 143ms/step - loss: 0.4187 - accuracy: 0.8333 - val_loss: 0.4619 - val_accuracy: 0.8300\n",
      "Epoch 14/20\n",
      "200/200 [==============================] - 29s 144ms/step - loss: 0.4092 - accuracy: 0.8464 - val_loss: 0.4580 - val_accuracy: 0.8338\n",
      "Epoch 15/20\n",
      "200/200 [==============================] - 28s 141ms/step - loss: 0.3973 - accuracy: 0.8462 - val_loss: 0.4598 - val_accuracy: 0.8350\n",
      "Epoch 16/20\n",
      "200/200 [==============================] - 28s 141ms/step - loss: 0.3939 - accuracy: 0.8489 - val_loss: 0.4552 - val_accuracy: 0.8288\n",
      "Epoch 17/20\n",
      "200/200 [==============================] - 28s 141ms/step - loss: 0.3859 - accuracy: 0.8520 - val_loss: 0.4505 - val_accuracy: 0.8325\n",
      "Epoch 18/20\n",
      "200/200 [==============================] - 28s 140ms/step - loss: 0.3825 - accuracy: 0.8512 - val_loss: 0.4511 - val_accuracy: 0.8350\n",
      "Epoch 19/20\n",
      "200/200 [==============================] - 28s 141ms/step - loss: 0.3714 - accuracy: 0.8580 - val_loss: 0.4546 - val_accuracy: 0.8375\n",
      "Epoch 20/20\n",
      "200/200 [==============================] - 28s 141ms/step - loss: 0.3694 - accuracy: 0.8552 - val_loss: 0.4506 - val_accuracy: 0.8375\n",
      "MFCC CNN\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_30 (Conv2D)           (None, 28, 37, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling (None, 14, 18, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 12, 16, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling (None, 6, 8, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 4, 6, 32)          4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_32 (MaxPooling (None, 2, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_23 (Flatten)         (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 64)                12352     \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 19,602\n",
      "Trainable params: 19,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.6668 - accuracy: 0.7484 - val_loss: 0.6355 - val_accuracy: 0.7563\n",
      "Epoch 2/20\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.6385 - accuracy: 0.7556 - val_loss: 0.6230 - val_accuracy: 0.7563\n",
      "Epoch 3/20\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.6220 - accuracy: 0.7556 - val_loss: 0.6109 - val_accuracy: 0.7563\n",
      "Epoch 4/20\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.6121 - accuracy: 0.7556 - val_loss: 0.6016 - val_accuracy: 0.7563\n",
      "Epoch 5/20\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.6085 - accuracy: 0.7556 - val_loss: 0.5958 - val_accuracy: 0.7563\n",
      "Epoch 6/20\n",
      "200/200 [==============================] - 3s 16ms/step - loss: 0.6016 - accuracy: 0.7556 - val_loss: 0.5915 - val_accuracy: 0.7563\n",
      "Epoch 7/20\n",
      "200/200 [==============================] - 3s 16ms/step - loss: 0.5962 - accuracy: 0.7556 - val_loss: 0.5885 - val_accuracy: 0.7563\n",
      "Epoch 8/20\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.5921 - accuracy: 0.7556 - val_loss: 0.5860 - val_accuracy: 0.7563\n",
      "Epoch 9/20\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.5878 - accuracy: 0.7556 - val_loss: 0.5858 - val_accuracy: 0.7563\n",
      "Epoch 10/20\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.5865 - accuracy: 0.7556 - val_loss: 0.5813 - val_accuracy: 0.7563\n",
      "Epoch 11/20\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.5883 - accuracy: 0.7556 - val_loss: 0.5790 - val_accuracy: 0.7563\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 3s 15ms/step - loss: 0.5829 - accuracy: 0.7556 - val_loss: 0.5775 - val_accuracy: 0.7563\n",
      "Epoch 13/20\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.5821 - accuracy: 0.7556 - val_loss: 0.5750 - val_accuracy: 0.7563\n",
      "Epoch 14/20\n",
      "200/200 [==============================] - 2s 10ms/step - loss: 0.5800 - accuracy: 0.7556 - val_loss: 0.5735 - val_accuracy: 0.7563\n",
      "Epoch 15/20\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 0.5787 - accuracy: 0.7556 - val_loss: 0.5720 - val_accuracy: 0.7563\n",
      "Epoch 16/20\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.5768 - accuracy: 0.7556 - val_loss: 0.5706 - val_accuracy: 0.7563\n",
      "Epoch 17/20\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.5760 - accuracy: 0.7556 - val_loss: 0.5694 - val_accuracy: 0.7563\n",
      "Epoch 18/20\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.5725 - accuracy: 0.7556 - val_loss: 0.5678 - val_accuracy: 0.7563\n",
      "Epoch 19/20\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.5742 - accuracy: 0.7556 - val_loss: 0.5670 - val_accuracy: 0.7563\n",
      "Epoch 20/20\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.5704 - accuracy: 0.7556 - val_loss: 0.5664 - val_accuracy: 0.7563\n",
      "VGG19\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_24 (Flatten)         (None, 6144)              0         \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 256)               1573120   \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 1,589,698\n",
      "Trainable params: 1,589,698\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.5978 - accuracy: 0.7481 - val_loss: 0.4204 - val_accuracy: 0.8125\n",
      "Epoch 2/20\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.4304 - accuracy: 0.8023 - val_loss: 0.4068 - val_accuracy: 0.8213\n",
      "Epoch 3/20\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.3930 - accuracy: 0.8192 - val_loss: 0.3887 - val_accuracy: 0.8238\n",
      "Epoch 4/20\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.3649 - accuracy: 0.8333 - val_loss: 0.3747 - val_accuracy: 0.8425\n",
      "Epoch 5/20\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.3510 - accuracy: 0.8375 - val_loss: 0.3717 - val_accuracy: 0.8438\n",
      "Epoch 6/20\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.3350 - accuracy: 0.8462 - val_loss: 0.4150 - val_accuracy: 0.8238\n",
      "Epoch 7/20\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.3156 - accuracy: 0.8545 - val_loss: 0.3706 - val_accuracy: 0.8425\n",
      "Epoch 8/20\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.3021 - accuracy: 0.8620 - val_loss: 0.3711 - val_accuracy: 0.8375\n",
      "Epoch 9/20\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.2981 - accuracy: 0.8675 - val_loss: 0.3655 - val_accuracy: 0.8425\n",
      "Epoch 10/20\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.2793 - accuracy: 0.8756 - val_loss: 0.3753 - val_accuracy: 0.8438\n",
      "Epoch 11/20\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.2693 - accuracy: 0.8809 - val_loss: 0.3660 - val_accuracy: 0.8450\n",
      "Epoch 12/20\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.2577 - accuracy: 0.8875 - val_loss: 0.3873 - val_accuracy: 0.8413\n",
      "Epoch 13/20\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.2512 - accuracy: 0.8881 - val_loss: 0.3955 - val_accuracy: 0.8400\n",
      "Epoch 14/20\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.2471 - accuracy: 0.8931 - val_loss: 0.4201 - val_accuracy: 0.8363\n",
      "Epoch 15/20\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.2280 - accuracy: 0.9003 - val_loss: 0.3959 - val_accuracy: 0.8462\n",
      "Epoch 16/20\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.2181 - accuracy: 0.9023 - val_loss: 0.4103 - val_accuracy: 0.8363\n",
      "Epoch 17/20\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.2142 - accuracy: 0.9062 - val_loss: 0.4208 - val_accuracy: 0.8475\n",
      "Epoch 18/20\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.2011 - accuracy: 0.9142 - val_loss: 0.4461 - val_accuracy: 0.8350\n",
      "Epoch 19/20\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.1850 - accuracy: 0.9202 - val_loss: 0.4349 - val_accuracy: 0.8313\n",
      "Epoch 20/20\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.1739 - accuracy: 0.9236 - val_loss: 0.4249 - val_accuracy: 0.8375\n",
      "VGG MFCC\n",
      "Epoch 1/20\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.4640 - accuracy: 0.7828 - val_loss: 0.3862 - val_accuracy: 0.8375\n",
      "Epoch 2/20\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.3867 - accuracy: 0.8216 - val_loss: 0.3700 - val_accuracy: 0.8475\n",
      "Epoch 3/20\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.3662 - accuracy: 0.8308 - val_loss: 0.3674 - val_accuracy: 0.8313\n",
      "Epoch 4/20\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.3485 - accuracy: 0.8377 - val_loss: 0.3562 - val_accuracy: 0.8388\n",
      "Epoch 5/20\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.3259 - accuracy: 0.8512 - val_loss: 0.3550 - val_accuracy: 0.8363\n",
      "Epoch 6/20\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.3085 - accuracy: 0.8597 - val_loss: 0.3615 - val_accuracy: 0.8225\n",
      "Epoch 7/20\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.3005 - accuracy: 0.8623 - val_loss: 0.3461 - val_accuracy: 0.8438\n",
      "Epoch 8/20\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.2836 - accuracy: 0.8714 - val_loss: 0.3352 - val_accuracy: 0.8500\n",
      "Epoch 9/20\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.2739 - accuracy: 0.8811 - val_loss: 0.3408 - val_accuracy: 0.8475\n",
      "Epoch 10/20\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.2621 - accuracy: 0.8814 - val_loss: 0.3366 - val_accuracy: 0.8475\n",
      "Epoch 11/20\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.2423 - accuracy: 0.8947 - val_loss: 0.3887 - val_accuracy: 0.8413\n",
      "Epoch 12/20\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.2407 - accuracy: 0.8923 - val_loss: 0.3460 - val_accuracy: 0.8500\n",
      "Epoch 13/20\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.2202 - accuracy: 0.9066 - val_loss: 0.3663 - val_accuracy: 0.8400\n",
      "Epoch 14/20\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.2075 - accuracy: 0.9087 - val_loss: 0.3699 - val_accuracy: 0.8350\n",
      "Epoch 15/20\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.2021 - accuracy: 0.9170 - val_loss: 0.3807 - val_accuracy: 0.8363\n",
      "Epoch 16/20\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.1892 - accuracy: 0.9192 - val_loss: 0.3800 - val_accuracy: 0.8313\n",
      "Epoch 17/20\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.1795 - accuracy: 0.9247 - val_loss: 0.4378 - val_accuracy: 0.8288\n",
      "Epoch 18/20\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.1692 - accuracy: 0.9305 - val_loss: 0.4021 - val_accuracy: 0.8375\n",
      "Epoch 19/20\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.1633 - accuracy: 0.9344 - val_loss: 0.4401 - val_accuracy: 0.8375\n",
      "Epoch 20/20\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.1505 - accuracy: 0.9402 - val_loss: 0.4208 - val_accuracy: 0.8450\n",
      "Time so far: 2845.0905220508575\n",
      "Index:  5\n",
      "Small CNN\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_33 (Conv2D)           (None, 126, 123, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_33 (MaxPooling (None, 63, 61, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 61, 59, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_34 (MaxPooling (None, 30, 29, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 28, 27, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_35 (MaxPooling (None, 14, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_27 (Flatten)         (None, 5824)              0         \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 5824)              0         \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 64)                372800    \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 380,338\n",
      "Trainable params: 380,338\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 27s 132ms/step - loss: 0.7879 - accuracy: 0.7262 - val_loss: 0.5587 - val_accuracy: 0.7850\n",
      "Epoch 2/20\n",
      "200/200 [==============================] - 348s 2s/step - loss: 0.5762 - accuracy: 0.7748 - val_loss: 0.5338 - val_accuracy: 0.7950\n",
      "Epoch 3/20\n",
      "200/200 [==============================] - 27s 135ms/step - loss: 0.5449 - accuracy: 0.7920 - val_loss: 0.5149 - val_accuracy: 0.8012\n",
      "Epoch 4/20\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.5263 - accuracy: 0.7992 - val_loss: 0.5044 - val_accuracy: 0.7987\n",
      "Epoch 5/20\n",
      "200/200 [==============================] - 25s 125ms/step - loss: 0.5086 - accuracy: 0.8073 - val_loss: 0.4939 - val_accuracy: 0.8100\n",
      "Epoch 6/20\n",
      "200/200 [==============================] - 27s 135ms/step - loss: 0.4975 - accuracy: 0.8112 - val_loss: 0.4870 - val_accuracy: 0.8087\n",
      "Epoch 7/20\n",
      "200/200 [==============================] - 29s 143ms/step - loss: 0.4799 - accuracy: 0.8172 - val_loss: 0.4728 - val_accuracy: 0.8125\n",
      "Epoch 8/20\n",
      "200/200 [==============================] - 28s 142ms/step - loss: 0.4649 - accuracy: 0.8214 - val_loss: 0.4670 - val_accuracy: 0.8188\n",
      "Epoch 9/20\n",
      "200/200 [==============================] - 29s 147ms/step - loss: 0.4563 - accuracy: 0.8222 - val_loss: 0.4664 - val_accuracy: 0.8238\n",
      "Epoch 10/20\n",
      "200/200 [==============================] - 29s 145ms/step - loss: 0.4449 - accuracy: 0.8258 - val_loss: 0.4537 - val_accuracy: 0.8175\n",
      "Epoch 11/20\n",
      "200/200 [==============================] - 29s 144ms/step - loss: 0.4378 - accuracy: 0.8308 - val_loss: 0.4465 - val_accuracy: 0.8200\n",
      "Epoch 12/20\n",
      "200/200 [==============================] - 29s 144ms/step - loss: 0.4281 - accuracy: 0.8311 - val_loss: 0.4504 - val_accuracy: 0.8188\n",
      "Epoch 13/20\n",
      "200/200 [==============================] - 29s 147ms/step - loss: 0.4183 - accuracy: 0.8363 - val_loss: 0.4333 - val_accuracy: 0.8225\n",
      "Epoch 14/20\n",
      "200/200 [==============================] - 31s 154ms/step - loss: 0.4141 - accuracy: 0.8377 - val_loss: 0.4403 - val_accuracy: 0.8175\n",
      "Epoch 15/20\n",
      "200/200 [==============================] - 31s 154ms/step - loss: 0.4073 - accuracy: 0.8409 - val_loss: 0.4332 - val_accuracy: 0.8263\n",
      "Epoch 16/20\n",
      "200/200 [==============================] - 29s 147ms/step - loss: 0.3980 - accuracy: 0.8458 - val_loss: 0.4255 - val_accuracy: 0.8225\n",
      "Epoch 17/20\n",
      "200/200 [==============================] - 29s 143ms/step - loss: 0.3917 - accuracy: 0.8400 - val_loss: 0.4295 - val_accuracy: 0.8350\n",
      "Epoch 18/20\n",
      "200/200 [==============================] - 29s 145ms/step - loss: 0.3840 - accuracy: 0.8484 - val_loss: 0.4301 - val_accuracy: 0.8275\n",
      "Epoch 19/20\n",
      "200/200 [==============================] - 29s 145ms/step - loss: 0.3778 - accuracy: 0.8498 - val_loss: 0.4313 - val_accuracy: 0.8275\n",
      "Epoch 20/20\n",
      "200/200 [==============================] - 29s 146ms/step - loss: 0.3762 - accuracy: 0.8505 - val_loss: 0.4231 - val_accuracy: 0.8338\n",
      "MFCC CNN\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_36 (Conv2D)           (None, 28, 37, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_36 (MaxPooling (None, 14, 18, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 12, 16, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_37 (MaxPooling (None, 6, 8, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 4, 6, 32)          4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_38 (MaxPooling (None, 2, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_28 (Flatten)         (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 64)                12352     \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 19,602\n",
      "Trainable params: 19,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 0.7140 - accuracy: 0.7041 - val_loss: 0.6351 - val_accuracy: 0.7550\n",
      "Epoch 2/20\n",
      "200/200 [==============================] - 3s 13ms/step - loss: 0.6365 - accuracy: 0.7555 - val_loss: 0.6179 - val_accuracy: 0.7550\n",
      "Epoch 3/20\n",
      "200/200 [==============================] - 3s 13ms/step - loss: 0.6238 - accuracy: 0.7556 - val_loss: 0.6074 - val_accuracy: 0.7550\n",
      "Epoch 4/20\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 0.6092 - accuracy: 0.7556 - val_loss: 0.5983 - val_accuracy: 0.7550\n",
      "Epoch 5/20\n",
      "200/200 [==============================] - 3s 13ms/step - loss: 0.6024 - accuracy: 0.7556 - val_loss: 0.5911 - val_accuracy: 0.7550\n",
      "Epoch 6/20\n",
      "200/200 [==============================] - 3s 13ms/step - loss: 0.5971 - accuracy: 0.7556 - val_loss: 0.5874 - val_accuracy: 0.7550\n",
      "Epoch 7/20\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 0.5903 - accuracy: 0.7556 - val_loss: 0.5830 - val_accuracy: 0.7550\n",
      "Epoch 8/20\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 0.5908 - accuracy: 0.7556 - val_loss: 0.5804 - val_accuracy: 0.7550\n",
      "Epoch 9/20\n",
      "200/200 [==============================] - 3s 13ms/step - loss: 0.5845 - accuracy: 0.7556 - val_loss: 0.5781 - val_accuracy: 0.7550\n",
      "Epoch 10/20\n",
      "200/200 [==============================] - 3s 13ms/step - loss: 0.5849 - accuracy: 0.7556 - val_loss: 0.5757 - val_accuracy: 0.7550\n",
      "Epoch 11/20\n",
      "200/200 [==============================] - 3s 13ms/step - loss: 0.5817 - accuracy: 0.7556 - val_loss: 0.5742 - val_accuracy: 0.7550\n",
      "Epoch 12/20\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 0.5798 - accuracy: 0.7556 - val_loss: 0.5730 - val_accuracy: 0.7550\n",
      "Epoch 13/20\n",
      "200/200 [==============================] - 3s 13ms/step - loss: 0.5800 - accuracy: 0.7556 - val_loss: 0.5714 - val_accuracy: 0.7550\n",
      "Epoch 14/20\n",
      "200/200 [==============================] - 3s 13ms/step - loss: 0.5767 - accuracy: 0.7556 - val_loss: 0.5701 - val_accuracy: 0.7550\n",
      "Epoch 15/20\n",
      "200/200 [==============================] - 3s 13ms/step - loss: 0.5747 - accuracy: 0.7556 - val_loss: 0.5690 - val_accuracy: 0.7550\n",
      "Epoch 16/20\n",
      "200/200 [==============================] - 3s 13ms/step - loss: 0.5754 - accuracy: 0.7556 - val_loss: 0.5681 - val_accuracy: 0.7550\n",
      "Epoch 17/20\n",
      "200/200 [==============================] - 3s 13ms/step - loss: 0.5724 - accuracy: 0.7556 - val_loss: 0.5683 - val_accuracy: 0.7550\n",
      "Epoch 18/20\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 0.5737 - accuracy: 0.7556 - val_loss: 0.5672 - val_accuracy: 0.7550\n",
      "Epoch 19/20\n",
      "200/200 [==============================] - 3s 13ms/step - loss: 0.5707 - accuracy: 0.7556 - val_loss: 0.5660 - val_accuracy: 0.7550\n",
      "Epoch 20/20\n",
      "200/200 [==============================] - 3s 13ms/step - loss: 0.5695 - accuracy: 0.7556 - val_loss: 0.5657 - val_accuracy: 0.7550\n",
      "VGG19\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_29 (Flatten)         (None, 6144)              0         \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 256)               1573120   \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 1,589,698\n",
      "Trainable params: 1,589,698\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 2s 7ms/step - loss: 0.5222 - accuracy: 0.7711 - val_loss: 0.3721 - val_accuracy: 0.8238\n",
      "Epoch 2/20\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.4228 - accuracy: 0.8052 - val_loss: 0.3600 - val_accuracy: 0.8300\n",
      "Epoch 3/20\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 0.3839 - accuracy: 0.8211 - val_loss: 0.3510 - val_accuracy: 0.8325\n",
      "Epoch 4/20\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 0.3640 - accuracy: 0.8267 - val_loss: 0.3417 - val_accuracy: 0.8338\n",
      "Epoch 5/20\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 0.3489 - accuracy: 0.8423 - val_loss: 0.3435 - val_accuracy: 0.8338\n",
      "Epoch 6/20\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 0.3333 - accuracy: 0.8483 - val_loss: 0.3283 - val_accuracy: 0.8462\n",
      "Epoch 7/20\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 0.3214 - accuracy: 0.8542 - val_loss: 0.3153 - val_accuracy: 0.8525\n",
      "Epoch 8/20\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.3098 - accuracy: 0.8609 - val_loss: 0.3210 - val_accuracy: 0.8500\n",
      "Epoch 9/20\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.3005 - accuracy: 0.8634 - val_loss: 0.3216 - val_accuracy: 0.8462\n",
      "Epoch 10/20\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 0.2852 - accuracy: 0.8709 - val_loss: 0.3277 - val_accuracy: 0.8462\n",
      "Epoch 11/20\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 0.2774 - accuracy: 0.8742 - val_loss: 0.3392 - val_accuracy: 0.8438\n",
      "Epoch 12/20\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.2619 - accuracy: 0.8820 - val_loss: 0.3250 - val_accuracy: 0.8537\n",
      "Epoch 13/20\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 0.2562 - accuracy: 0.8838 - val_loss: 0.3262 - val_accuracy: 0.8537\n",
      "Epoch 14/20\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.2474 - accuracy: 0.8914 - val_loss: 0.3403 - val_accuracy: 0.8438\n",
      "Epoch 15/20\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 0.2402 - accuracy: 0.8948 - val_loss: 0.3321 - val_accuracy: 0.8475\n",
      "Epoch 16/20\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.2273 - accuracy: 0.9009 - val_loss: 0.3254 - val_accuracy: 0.8500\n",
      "Epoch 17/20\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 0.2159 - accuracy: 0.9045 - val_loss: 0.3424 - val_accuracy: 0.8450\n",
      "Epoch 18/20\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.2077 - accuracy: 0.9086 - val_loss: 0.3368 - val_accuracy: 0.8525\n",
      "Epoch 19/20\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 0.1945 - accuracy: 0.9128 - val_loss: 0.3673 - val_accuracy: 0.8475\n",
      "Epoch 20/20\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.1821 - accuracy: 0.9216 - val_loss: 0.3513 - val_accuracy: 0.8537\n",
      "VGG MFCC\n",
      "Epoch 1/20\n",
      "200/200 [==============================] - 2s 7ms/step - loss: 0.4509 - accuracy: 0.7919 - val_loss: 0.3612 - val_accuracy: 0.8213\n",
      "Epoch 2/20\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 0.3885 - accuracy: 0.8208 - val_loss: 0.3410 - val_accuracy: 0.8462\n",
      "Epoch 3/20\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.3563 - accuracy: 0.8395 - val_loss: 0.3371 - val_accuracy: 0.8475\n",
      "Epoch 4/20\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.3403 - accuracy: 0.8444 - val_loss: 0.3322 - val_accuracy: 0.8500\n",
      "Epoch 5/20\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 0.3191 - accuracy: 0.8552 - val_loss: 0.3173 - val_accuracy: 0.8500\n",
      "Epoch 6/20\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 0.3066 - accuracy: 0.8591 - val_loss: 0.3281 - val_accuracy: 0.8487\n",
      "Epoch 7/20\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 0.2922 - accuracy: 0.8673 - val_loss: 0.3194 - val_accuracy: 0.8525\n",
      "Epoch 8/20\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.2787 - accuracy: 0.8742 - val_loss: 0.3183 - val_accuracy: 0.8512\n",
      "Epoch 9/20\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.2705 - accuracy: 0.8772 - val_loss: 0.3157 - val_accuracy: 0.8500\n",
      "Epoch 10/20\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.2486 - accuracy: 0.8928 - val_loss: 0.3156 - val_accuracy: 0.8562\n",
      "Epoch 11/20\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.2369 - accuracy: 0.8970 - val_loss: 0.3743 - val_accuracy: 0.8275\n",
      "Epoch 12/20\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.2380 - accuracy: 0.8947 - val_loss: 0.3193 - val_accuracy: 0.8500\n",
      "Epoch 13/20\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.2135 - accuracy: 0.9092 - val_loss: 0.3132 - val_accuracy: 0.8550\n",
      "Epoch 14/20\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.2054 - accuracy: 0.9120 - val_loss: 0.3337 - val_accuracy: 0.8537\n",
      "Epoch 15/20\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 0.1937 - accuracy: 0.9183 - val_loss: 0.3412 - val_accuracy: 0.8525\n",
      "Epoch 16/20\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.1810 - accuracy: 0.9216 - val_loss: 0.3386 - val_accuracy: 0.8562\n",
      "Epoch 17/20\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 0.1753 - accuracy: 0.9275 - val_loss: 0.3471 - val_accuracy: 0.8500\n",
      "Epoch 18/20\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.1642 - accuracy: 0.9297 - val_loss: 0.3510 - val_accuracy: 0.8500\n",
      "Epoch 19/20\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 0.1560 - accuracy: 0.9372 - val_loss: 0.3408 - val_accuracy: 0.8612\n",
      "Epoch 20/20\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 0.1486 - accuracy: 0.9402 - val_loss: 0.3793 - val_accuracy: 0.8338\n",
      "Time so far: 3855.6556293964386\n",
      "Index:  6\n",
      "Small CNN\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_39 (Conv2D)           (None, 126, 123, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_39 (MaxPooling (None, 63, 61, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 61, 59, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_40 (MaxPooling (None, 30, 29, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 28, 27, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_41 (MaxPooling (None, 14, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_32 (Flatten)         (None, 5824)              0         \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 5824)              0         \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 64)                372800    \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 380,338\n",
      "Trainable params: 380,338\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "200/200 [==============================] - 31s 151ms/step - loss: 0.9176 - accuracy: 0.7212 - val_loss: 0.5841 - val_accuracy: 0.7975\n",
      "Epoch 2/20\n",
      "200/200 [==============================] - 31s 153ms/step - loss: 0.6082 - accuracy: 0.7634 - val_loss: 0.5640 - val_accuracy: 0.7925\n",
      "Epoch 3/20\n",
      "200/200 [==============================] - 29s 143ms/step - loss: 0.5782 - accuracy: 0.7856 - val_loss: 0.5397 - val_accuracy: 0.8062\n",
      "Epoch 4/20\n",
      "200/200 [==============================] - 28s 142ms/step - loss: 0.5427 - accuracy: 0.7925 - val_loss: 0.5372 - val_accuracy: 0.8012\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 28s 139ms/step - loss: 0.5264 - accuracy: 0.8025 - val_loss: 0.5085 - val_accuracy: 0.8075\n",
      "Epoch 6/20\n",
      "200/200 [==============================] - 28s 139ms/step - loss: 0.5144 - accuracy: 0.8045 - val_loss: 0.4977 - val_accuracy: 0.8138\n",
      "Epoch 7/20\n",
      "200/200 [==============================] - 28s 140ms/step - loss: 0.5003 - accuracy: 0.8108 - val_loss: 0.4863 - val_accuracy: 0.8163\n",
      "Epoch 8/20\n",
      "200/200 [==============================] - 28s 140ms/step - loss: 0.4822 - accuracy: 0.8141 - val_loss: 0.4772 - val_accuracy: 0.8213\n",
      "Epoch 9/20\n",
      "200/200 [==============================] - 28s 141ms/step - loss: 0.4752 - accuracy: 0.8153 - val_loss: 0.4690 - val_accuracy: 0.8163\n",
      "Epoch 10/20\n",
      "200/200 [==============================] - 28s 140ms/step - loss: 0.4667 - accuracy: 0.8252 - val_loss: 0.4697 - val_accuracy: 0.8188\n",
      "Epoch 11/20\n",
      "200/200 [==============================] - 28s 141ms/step - loss: 0.4595 - accuracy: 0.8200 - val_loss: 0.4647 - val_accuracy: 0.8200\n",
      "Epoch 12/20\n",
      "200/200 [==============================] - 28s 142ms/step - loss: 0.4530 - accuracy: 0.8248 - val_loss: 0.4573 - val_accuracy: 0.8200\n",
      "Epoch 13/20\n",
      "200/200 [==============================] - 29s 144ms/step - loss: 0.4441 - accuracy: 0.8292 - val_loss: 0.4529 - val_accuracy: 0.8225\n",
      "Epoch 14/20\n",
      "200/200 [==============================] - 28s 140ms/step - loss: 0.4345 - accuracy: 0.8292 - val_loss: 0.4576 - val_accuracy: 0.8075\n",
      "Epoch 15/20\n",
      "200/200 [==============================] - 28s 141ms/step - loss: 0.4191 - accuracy: 0.8377 - val_loss: 0.4476 - val_accuracy: 0.8238\n",
      "Epoch 16/20\n",
      "200/200 [==============================] - 28s 142ms/step - loss: 0.4156 - accuracy: 0.8370 - val_loss: 0.4366 - val_accuracy: 0.8325\n",
      "Epoch 17/20\n",
      "200/200 [==============================] - 28s 141ms/step - loss: 0.4141 - accuracy: 0.8398 - val_loss: 0.4345 - val_accuracy: 0.8250\n",
      "Epoch 18/20\n",
      "200/200 [==============================] - 28s 141ms/step - loss: 0.4038 - accuracy: 0.8439 - val_loss: 0.4311 - val_accuracy: 0.8263\n",
      "Epoch 19/20\n",
      "200/200 [==============================] - 28s 142ms/step - loss: 0.4018 - accuracy: 0.8369 - val_loss: 0.4264 - val_accuracy: 0.8263\n",
      "Epoch 20/20\n",
      "200/200 [==============================] - 28s 142ms/step - loss: 0.3941 - accuracy: 0.8494 - val_loss: 0.4253 - val_accuracy: 0.8213\n",
      "MFCC CNN\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_42 (Conv2D)           (None, 28, 37, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_42 (MaxPooling (None, 14, 18, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 12, 16, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_43 (MaxPooling (None, 6, 8, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 4, 6, 32)          4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_44 (MaxPooling (None, 2, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_33 (Flatten)         (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 64)                12352     \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 19,602\n",
      "Trainable params: 19,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 0.6972 - accuracy: 0.7153 - val_loss: 0.6310 - val_accuracy: 0.7563\n",
      "Epoch 2/20\n",
      "200/200 [==============================] - 2s 11ms/step - loss: 0.6344 - accuracy: 0.7556 - val_loss: 0.6156 - val_accuracy: 0.7563\n",
      "Epoch 3/20\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 0.6236 - accuracy: 0.7556 - val_loss: 0.6038 - val_accuracy: 0.7563\n",
      "Epoch 4/20\n",
      "200/200 [==============================] - 2s 12ms/step - loss: 0.6118 - accuracy: 0.7556 - val_loss: 0.5955 - val_accuracy: 0.7563\n",
      "Epoch 5/20\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 0.6032 - accuracy: 0.7556 - val_loss: 0.5893 - val_accuracy: 0.7563\n",
      "Epoch 6/20\n",
      "200/200 [==============================] - 3s 16ms/step - loss: 0.5946 - accuracy: 0.7556 - val_loss: 0.5847 - val_accuracy: 0.7563\n",
      "Epoch 7/20\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.5905 - accuracy: 0.7556 - val_loss: 0.5812 - val_accuracy: 0.7563\n",
      "Epoch 8/20\n",
      "200/200 [==============================] - 3s 13ms/step - loss: 0.5848 - accuracy: 0.7556 - val_loss: 0.5784 - val_accuracy: 0.7563\n",
      "Epoch 9/20\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 0.5842 - accuracy: 0.7556 - val_loss: 0.5761 - val_accuracy: 0.7563\n",
      "Epoch 10/20\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 0.5801 - accuracy: 0.7556 - val_loss: 0.5756 - val_accuracy: 0.7563\n",
      "Epoch 11/20\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 0.5801 - accuracy: 0.7556 - val_loss: 0.5741 - val_accuracy: 0.7563\n",
      "Epoch 12/20\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 0.5780 - accuracy: 0.7556 - val_loss: 0.5715 - val_accuracy: 0.7563\n",
      "Epoch 13/20\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 0.5738 - accuracy: 0.7556 - val_loss: 0.5722 - val_accuracy: 0.7563\n",
      "Epoch 14/20\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 0.5744 - accuracy: 0.7556 - val_loss: 0.5687 - val_accuracy: 0.7563\n",
      "Epoch 15/20\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 0.5726 - accuracy: 0.7556 - val_loss: 0.5678 - val_accuracy: 0.7563\n",
      "Epoch 16/20\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 0.5705 - accuracy: 0.7556 - val_loss: 0.5680 - val_accuracy: 0.7563\n",
      "Epoch 17/20\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 0.5696 - accuracy: 0.7556 - val_loss: 0.5675 - val_accuracy: 0.7563\n",
      "Epoch 18/20\n",
      "200/200 [==============================] - 2s 12ms/step - loss: 0.5693 - accuracy: 0.7556 - val_loss: 0.5643 - val_accuracy: 0.7563\n",
      "Epoch 19/20\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.5657 - accuracy: 0.7556 - val_loss: 0.5636 - val_accuracy: 0.7563\n",
      "Epoch 20/20\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 0.5660 - accuracy: 0.7556 - val_loss: 0.5620 - val_accuracy: 0.7563\n",
      "VGG19\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_34 (Flatten)         (None, 6144)              0         \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 256)               1573120   \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 1,589,698\n",
      "Trainable params: 1,589,698\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "200/200 [==============================] - 2s 7ms/step - loss: 0.5318 - accuracy: 0.7628 - val_loss: 0.3960 - val_accuracy: 0.8200\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 1s 7ms/step - loss: 0.4263 - accuracy: 0.8025 - val_loss: 0.3726 - val_accuracy: 0.8450\n",
      "Epoch 3/20\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 0.3876 - accuracy: 0.8188 - val_loss: 0.3693 - val_accuracy: 0.8400\n",
      "Epoch 4/20\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 0.3655 - accuracy: 0.8313 - val_loss: 0.3505 - val_accuracy: 0.8500\n",
      "Epoch 5/20\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.3505 - accuracy: 0.8430 - val_loss: 0.3531 - val_accuracy: 0.8562\n",
      "Epoch 6/20\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.3328 - accuracy: 0.8500 - val_loss: 0.3614 - val_accuracy: 0.8338\n",
      "Epoch 7/20\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.3240 - accuracy: 0.8486 - val_loss: 0.3404 - val_accuracy: 0.8650\n",
      "Epoch 8/20\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.3098 - accuracy: 0.8591 - val_loss: 0.3418 - val_accuracy: 0.8562\n",
      "Epoch 9/20\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.3038 - accuracy: 0.8630 - val_loss: 0.3533 - val_accuracy: 0.8537\n",
      "Epoch 10/20\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 0.2902 - accuracy: 0.8675 - val_loss: 0.3447 - val_accuracy: 0.8475\n",
      "Epoch 11/20\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 0.2794 - accuracy: 0.8742 - val_loss: 0.3597 - val_accuracy: 0.8450\n",
      "Epoch 12/20\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 0.2696 - accuracy: 0.8825 - val_loss: 0.3588 - val_accuracy: 0.8512\n",
      "Epoch 13/20\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 0.2617 - accuracy: 0.8833 - val_loss: 0.3520 - val_accuracy: 0.8612\n",
      "Epoch 14/20\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 0.2522 - accuracy: 0.8877 - val_loss: 0.3589 - val_accuracy: 0.8575\n",
      "Epoch 15/20\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 0.2388 - accuracy: 0.8928 - val_loss: 0.3662 - val_accuracy: 0.8475\n",
      "Epoch 16/20\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 0.2339 - accuracy: 0.9005 - val_loss: 0.3669 - val_accuracy: 0.8450\n",
      "Epoch 17/20\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.2212 - accuracy: 0.9016 - val_loss: 0.3715 - val_accuracy: 0.8537\n",
      "Epoch 18/20\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.2101 - accuracy: 0.9052 - val_loss: 0.3770 - val_accuracy: 0.8600\n",
      "Epoch 19/20\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.2035 - accuracy: 0.9125 - val_loss: 0.3788 - val_accuracy: 0.8550\n",
      "Epoch 20/20\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 0.1944 - accuracy: 0.9194 - val_loss: 0.4023 - val_accuracy: 0.8537\n",
      "VGG MFCC\n",
      "Epoch 1/20\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.4640 - accuracy: 0.7841 - val_loss: 0.3861 - val_accuracy: 0.8163\n",
      "Epoch 2/20\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 0.3892 - accuracy: 0.8134 - val_loss: 0.3754 - val_accuracy: 0.8225\n",
      "Epoch 3/20\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 0.3623 - accuracy: 0.8311 - val_loss: 0.3569 - val_accuracy: 0.8512\n",
      "Epoch 4/20\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 0.3468 - accuracy: 0.8363 - val_loss: 0.3696 - val_accuracy: 0.8438\n",
      "Epoch 5/20\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.3243 - accuracy: 0.8553 - val_loss: 0.3472 - val_accuracy: 0.8487\n",
      "Epoch 6/20\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.3159 - accuracy: 0.8528 - val_loss: 0.3426 - val_accuracy: 0.8550\n",
      "Epoch 7/20\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.2953 - accuracy: 0.8634 - val_loss: 0.3477 - val_accuracy: 0.8575\n",
      "Epoch 8/20\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 0.2841 - accuracy: 0.8755 - val_loss: 0.3491 - val_accuracy: 0.8562\n",
      "Epoch 9/20\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 0.2732 - accuracy: 0.8778 - val_loss: 0.3601 - val_accuracy: 0.8500\n",
      "Epoch 10/20\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 0.2576 - accuracy: 0.8875 - val_loss: 0.3528 - val_accuracy: 0.8600\n",
      "Epoch 11/20\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 0.2517 - accuracy: 0.8897 - val_loss: 0.3473 - val_accuracy: 0.8562\n",
      "Epoch 12/20\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.2349 - accuracy: 0.8972 - val_loss: 0.3582 - val_accuracy: 0.8562\n",
      "Epoch 13/20\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.2249 - accuracy: 0.9025 - val_loss: 0.3666 - val_accuracy: 0.8625\n",
      "Epoch 14/20\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 0.2153 - accuracy: 0.9084 - val_loss: 0.3557 - val_accuracy: 0.8587\n",
      "Epoch 15/20\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.2010 - accuracy: 0.9181 - val_loss: 0.3777 - val_accuracy: 0.8550\n",
      "Epoch 16/20\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.1880 - accuracy: 0.9230 - val_loss: 0.3675 - val_accuracy: 0.8700\n",
      "Epoch 17/20\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 0.1749 - accuracy: 0.9277 - val_loss: 0.3738 - val_accuracy: 0.8625\n",
      "Epoch 18/20\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 0.1644 - accuracy: 0.9331 - val_loss: 0.3958 - val_accuracy: 0.8600\n",
      "Epoch 19/20\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.1639 - accuracy: 0.9312 - val_loss: 0.4228 - val_accuracy: 0.8587\n",
      "Epoch 20/20\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.1512 - accuracy: 0.9375 - val_loss: 0.3978 - val_accuracy: 0.8650\n",
      "Time so far: 4545.501451253891\n",
      "Index:  7\n",
      "Small CNN\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_45 (Conv2D)           (None, 126, 123, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_45 (MaxPooling (None, 63, 61, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_46 (Conv2D)           (None, 61, 59, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_46 (MaxPooling (None, 30, 29, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 28, 27, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_47 (MaxPooling (None, 14, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_37 (Flatten)         (None, 5824)              0         \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 5824)              0         \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 64)                372800    \n",
      "_________________________________________________________________\n",
      "dropout_46 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 380,338\n",
      "Trainable params: 380,338\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      " 24/200 [==>...........................] - ETA: 21s - loss: 2.1483 - accuracy: 0.5951"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-70-54e4b76e1c55>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     main_model_run_loaded(filenames, i,\n\u001b[0m\u001b[0;32m      3\u001b[0m                           \u001b[0mspec_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_labs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                           \u001b[0mvgg_X\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                           \u001b[0mmfcc_X\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-65-a3ced3146929>\u001b[0m in \u001b[0;36mmain_model_run_loaded\u001b[1;34m(filenames, index, X, y_labs, vgg_X, mfcc_X, ind_X, small_cnn, mfcc_cnn, vgg19, vgg_mfcc, vgg_ind, vgg_mfcc_ind)\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[0mfilename_run\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilename_idx\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m         history = model.fit(X_train, y_train,\n\u001b[0m\u001b[0;32m     64\u001b[0m                             \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m                             \u001b[0mcallbacks\u001b[0m       \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbest_model_cp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1182\u001b[0m                 _r=1):\n\u001b[0;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3037\u001b[0m       (graph_function,\n\u001b[0;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3039\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1962\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1963\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(4,10+1):\n",
    "    main_model_run_loaded(filenames, i,\n",
    "                          spec_X, y_labs,\n",
    "                          vgg_X,\n",
    "                          mfcc_X,\n",
    "                          ind_X = [],\n",
    "                          vgg_ind  = False,\n",
    "                          vgg_mfcc_ind = False)#,\n",
    "                    #smallcnn_mfcc = True)\n",
    "    print(\"Time so far:\", time.time() - tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc963a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "toc = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "66263a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#librosa.load('richfield_birds_split/Common Kestrel/xc672833_start_1_30.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b41b66e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2606.4441616535187\n"
     ]
    }
   ],
   "source": [
    "print(toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "dea6ac17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(res_df_t.to_latex(bold_rows = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1f9fb407",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!zip -r results.zip results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
