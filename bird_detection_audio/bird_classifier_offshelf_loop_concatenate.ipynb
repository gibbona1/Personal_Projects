{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6db40fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16, VGG19, ResNet50\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd7bf22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score, auc\n",
    "import plotly.figure_factory as ff\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from data_set_params import DataSetParams\n",
    "from scipy.io import wavfile\n",
    "params = DataSetParams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4762bcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#\n",
    "#def get_size(start_path = '.'):\n",
    "#    total_size = 0\n",
    "#    for dirpath, dirnames, filenames in os.walk(start_path):\n",
    "#        for f in filenames:\n",
    "#            fp = os.path.join(dirpath, f)\n",
    "#            # skip if it is symbolic link\n",
    "#            if not os.path.islink(fp):\n",
    "#                print(fp)\n",
    "#                print(\"\\tsize:\", os.path.getsize(fp))\n",
    "#                total_size += os.path.getsize(fp)\n",
    "#\n",
    "#    return total_size\n",
    "#total_size = get_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7da91cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(total_size, 'bytes')\n",
    "#print(total_size/(1024), 'kilobytes')\n",
    "#print(total_size/(1024**2), 'megabytes')\n",
    "#print(total_size/(1024**3), 'gigabytes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8f2b444",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d40c7058",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!zip -r models_20220303.zip models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4508835d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!zip -r results.zip results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "443712a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! unzip ~/data/wav_clips.zip -d ~/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c632404",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! unzip ~/data/ff1010bird.zip -d ~/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c155b282",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f76304dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ff1010bird_meta = pd.read_csv('C:\\\\Users\\\\Anthony\\\\Downloads\\\\ff1010bird_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0269a5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemid</th>\n",
       "      <th>hasbird</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64486</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2525</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44981</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101323</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>165746</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7685</th>\n",
       "      <td>168059</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7686</th>\n",
       "      <td>164922</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7687</th>\n",
       "      <td>80789</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7688</th>\n",
       "      <td>104733</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7689</th>\n",
       "      <td>40565</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7690 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      itemid  hasbird\n",
       "0      64486        0\n",
       "1       2525        0\n",
       "2      44981        0\n",
       "3     101323        0\n",
       "4     165746        0\n",
       "...      ...      ...\n",
       "7685  168059        0\n",
       "7686  164922        0\n",
       "7687   80789        1\n",
       "7688  104733        1\n",
       "7689   40565        0\n",
       "\n",
       "[7690 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff1010bird_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0a6452e",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_dict = {0: 'not_bird',\n",
    "          1: 'bird'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e11a32b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.mkdir(os.path.join(data_dir, 'bird'))\n",
    "#os.mkdir(os.path.join(data_dir, 'not_bird'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f15391c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.rename(data_dir, \"path/to/new/destination/for/file.foo\")\n",
    "#os.listdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "418da0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i,row in ff1010bird_meta.iterrows():\n",
    "#    st_dir  = os.path.join(data_dir, str(row.itemid)+'.wav')\n",
    "#    sav_dir = os.path.join(data_dir, b_dict[row.hasbird], str(row.itemid)+'.wav')\n",
    "    #print(st_dir)\n",
    "    #print()\n",
    "#    os.rename(st_dir, sav_dir)\n",
    "    #print(row.itemid)\n",
    "    #print(row.hasbird)\n",
    "    #print(str(row.itemid)+'.wav' in os.listdir(data_dir))\n",
    "    #print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a29d33f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir   = 'C:\\\\Users\\\\Anthony\\\\Downloads\\\\ff1010bird\\\\ff1010bird_wav\\\\wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d372333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bird', 'not_bird']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data_dir = pathlib.Path('/root/tensorflow_datasets/downloads/extracted/TAR_GZ.opihi.cs.uvic.ca_sound_music_speechbya81rFcWfLSW6ey5cynqyeq2qiePcL-7asMoNO6IQ0.tar.gz/music_speech')\n",
    "#data_dir   = 'C:\\\\Users\\\\Anthony\\\\Downloads\\\\ff1010bird\\\\ff1010bird_wav\\\\wav'#'richfield_birds_split'#'dublin_dl_birds_split'#\n",
    "categories = np.array(tf.io.gfile.listdir(data_dir))\n",
    "categories = [category for category in categories if 'wav' not in category and '.TAG' not in category]\n",
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "65a230e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(file_path):\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "\n",
    "    # Note: You'll use indexing here instead of tuple unpacking to enable this \n",
    "    # to work in a TensorFlow graph.\n",
    "    return parts[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "071ce280",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preload_vgg19(input_shape):\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=input_shape),\n",
    "        Flatten(), # Flatten dimensions to for use in FC layers\n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.5), # Dropout layer to reduce overfitting\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(num_classes, activation='softmax') # Softmax for multiclass\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer = optimizers.Adam(learning_rate=0.0001),\n",
    "        loss      = losses.SparseCategoricalCrossentropy(),\n",
    "        metrics   = 'accuracy'\n",
    "        )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a06054a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preload_vgg19_concat(input_shape, num_channels):\n",
    "    from tensorflow.keras.layers import concatenate\n",
    "    out_list   = []\n",
    "    input_list = []\n",
    "    for c in range(num_channels):\n",
    "        input_a = layers.Input(shape=input_shape)\n",
    "        input_list.append(input_a)\n",
    "        #out_list.append(vgg_model.output)\n",
    "    #vgg_model.summary()\n",
    "    #x = vgg_model.output\n",
    "    concatenated = concatenate(input_list, axis=-1)\n",
    "    x = Flatten()(concatenated) # Flatten dimensions to for use in FC layers\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x) # Dropout layer to reduce overfitting\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dense(num_classes, activation='softmax')(x) # Softmax for multiclass\n",
    "    concat_vgg_model = Model(inputs=input_list, outputs=x)\n",
    "    concat_vgg_model.compile(\n",
    "        optimizer = optimizers.Adam(learning_rate=0.0001),\n",
    "        loss      = losses.SparseCategoricalCrossentropy(),\n",
    "        metrics   = 'accuracy'\n",
    "        )\n",
    "    return concat_vgg_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "489e0477",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = tf.io.gfile.glob(str(data_dir) + '/*/*')\n",
    "#filenames = tf.io.gfile.glob('birds/*/*')\n",
    "filenames = [filename for filename in filenames if 'wav' in filename]\n",
    "filenames = tf.random.shuffle(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "42367d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE   = tf.data.experimental.AUTOTUNE\n",
    "batch_size = 32\n",
    "EPOCHS     = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd6c4b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "247c71d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3f2f66cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, roc_auc_score, top_k_accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from math import prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a9b75f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(model, x_test, y_true, name, filename_run, index):\n",
    "        #model.save('models/'+filename_run+'.h5')\n",
    "    \n",
    "        pred_lists = model.predict(x_test)\n",
    "        y_pred     = np.argmax(pred_lists, axis=-1)\n",
    "        pred_df    = pd.DataFrame(pred_lists, columns = categories)\n",
    "        \n",
    "        softmax_prediction_df = pred_df.apply(lambda x: np.exp(x - np.max(x))/np.exp(x - np.max(x)).sum(), axis=1)\n",
    "        softmax_prediction_df.to_csv('results/'+filename_run+'_softmax_prediction_df.csv')\n",
    "        \n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        fig = plotly_cm(cm, categories)\n",
    "        fig.write_html('results/'+filename_run+'_confusion_matrix.html')\n",
    "        \n",
    "        num_trainable    = sum([prod(w.shape) for w in model.trainable_weights])\n",
    "        num_nontrainable = sum([prod(w.shape) for w in model.non_trainable_weights])\n",
    "        \n",
    "        onehot_data = OneHotEncoder(sparse=False)\n",
    "        onehot_data = onehot_data.fit_transform(np.array(y_true).reshape(len(y_true),1))\n",
    "        roc_auc = [0]*num_classes\n",
    "        \n",
    "        for i in range(num_classes):\n",
    "            roc_auc[i] = roc_auc_score(onehot_data[:, i], softmax_prediction_df.to_numpy()[:, i])\n",
    "        \n",
    "        name_df = pd.DataFrame(data={\n",
    "                  'model':     name}, index=[index])\n",
    "        metric_df = pd.DataFrame(data={\n",
    "                  'top_1_acc': [accuracy_score(y_pred, y_true)],\n",
    "                  #'top_5_acc': [top_k_accuracy_score(y_true, softmax_prediction_df, k=5)],\n",
    "                  'precision': [precision_score(y_pred, y_true, average = 'weighted')], \n",
    "                  'f1':        [f1_score(y_pred, y_true, average = 'weighted')]\n",
    "                 })\n",
    "        param_df = pd.DataFrame(data={\n",
    "                  'trainable_params': [num_trainable],\n",
    "                  'nontrainable_params': [num_nontrainable]\n",
    "                 })\n",
    "        auc_df = pd.DataFrame([roc_auc], columns = ['auc_'+categories[i].replace(' ', '') for i in range(num_classes)])\n",
    "        \n",
    "        metric_df =  pd.concat([name_df, metric_df],axis=1)\n",
    "        metric_df.to_csv('results/'+filename_run+'_metric_df.csv')\n",
    "        \n",
    "        param_df  =  pd.concat([name_df, param_df],axis=1)\n",
    "        param_df.to_csv('results/'+filename_run+'_param_df.csv')\n",
    "        \n",
    "        auc_df    =  pd.concat([name_df, auc_df],axis=1)\n",
    "        auc_df.to_csv('results/'+filename_run+'_auc_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3795af9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vgg19(input_shape):\n",
    "    vgg_model = VGG19(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    vgg_model.trainable = False ## Not trainable weights\n",
    "    #vgg_model.summary()\n",
    "    x = vgg_model.output\n",
    "    x = Flatten()(x) # Flatten dimensions to for use in FC layers\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x) # Dropout layer to reduce overfitting\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dense(num_classes, activation='softmax')(x) # Softmax for multiclass\n",
    "    transfer_vgg_model = Model(inputs=vgg_model.input, outputs=x)\n",
    "    transfer_vgg_model.compile(\n",
    "        optimizer = optimizers.Adam(learning_rate=0.0001),\n",
    "        loss      = losses.SparseCategoricalCrossentropy(),\n",
    "        metrics   = 'accuracy'\n",
    "        )\n",
    "    return transfer_vgg_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982709cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "086337af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vgg19_concat(input_shape, num_channels):\n",
    "    from tensorflow.keras.layers import concatenate\n",
    "    out_list   = []\n",
    "    input_list = []\n",
    "    for c in range(num_channels):\n",
    "        vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "        vgg_model._name = vgg_model._name + str(c)\n",
    "        for layer in vgg_model.layers:\n",
    "            layer._name = layer._name + '_' + str(c)\n",
    "        vgg_model.trainable = False ## Not trainable weights\n",
    "        input_a = vgg_model.input\n",
    "        input_list.append(input_a)\n",
    "        out_list.append(vgg_model.output)\n",
    "    #vgg_model.summary()\n",
    "    #x = vgg_model.output\n",
    "    concatenated = concatenate(out_list)\n",
    "    x = Flatten()(concatenated) # Flatten dimensions to for use in FC layers\n",
    "    x = Dense(256*num_channels, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x) # Dropout layer to reduce overfitting\n",
    "    x = Dense(64*num_channels, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x) # Dropout layer to reduce overfitting\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dense(num_classes, activation='softmax')(x) # Softmax for multiclass\n",
    "    concat_vgg_model = Model(inputs=input_list, outputs=x)\n",
    "    concat_vgg_model.compile(\n",
    "        optimizer = optimizers.Adam(learning_rate=0.0001),\n",
    "        loss      = losses.SparseCategoricalCrossentropy(),\n",
    "        metrics   = 'accuracy'\n",
    "        )\n",
    "    return concat_vgg_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b5f530d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_resnet50(input_shape):\n",
    "    resnet_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    resnet_model.trainable = False ## Not trainable weights\n",
    "    #resnet_model.summary()\n",
    "    x = resnet_model.output\n",
    "    x = Flatten()(x) # Flatten dimensions to for use in FC layers\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x) # Dropout layer to reduce overfitting\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dense(num_classes, activation='softmax')(x) # Softmax for multiclass\n",
    "    transfer_resnet_model = Model(inputs=resnet_model.input, outputs=x)\n",
    "    transfer_resnet_model.compile(\n",
    "        optimizer = optimizers.Adam(learning_rate=0.0001),\n",
    "        loss      = losses.SparseCategoricalCrossentropy(),\n",
    "        metrics   = 'accuracy'\n",
    "        )\n",
    "    return transfer_resnet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f162967b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_resnet50_concat(input_shape, num_channels):\n",
    "    from tensorflow.keras.layers import concatenate\n",
    "    out_list   = []\n",
    "    input_list = []\n",
    "    for c in range(num_channels):\n",
    "        resnet_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "        resnet_model._name = resnet_model._name + str(c)\n",
    "        for layer in resnet_model.layers:\n",
    "            layer._name = layer._name + '_' + str(c)\n",
    "        resnet_model.trainable = False ## Not trainable weights\n",
    "        input_a = resnet_model.input\n",
    "        input_list.append(input_a)\n",
    "        out_list.append(resnet_model.output)\n",
    "    #vgg_model.summary()\n",
    "    #x = vgg_model.output\n",
    "    concatenated = concatenate(out_list)\n",
    "    x = Flatten()(concatenated) # Flatten dimensions to for use in FC layers\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x) # Dropout layer to reduce overfitting\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dense(num_classes, activation='softmax')(x) # Softmax for multiclass\n",
    "    concat_resnet_model = Model(inputs=input_list, outputs=x)\n",
    "    concat_resnet_model.compile(\n",
    "        optimizer = optimizers.Adam(learning_rate=0.0001),\n",
    "        loss      = losses.SparseCategoricalCrossentropy(),\n",
    "        metrics   = 'accuracy'\n",
    "        )\n",
    "    return concat_resnet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1304621e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_model_run(filenames, index,\n",
    "                   vgg19        = False,\n",
    "                   vgg19_concat = False,\n",
    "                   resnet50     = False,\n",
    "                   resnet50_concat = False,\n",
    "                   smallcnn = False,\n",
    "                   concat   = False,\n",
    "                   concat2  = False,\n",
    "                   concat3  = False,\n",
    "                   concat4  = False):\n",
    "    print(\"Index: \", index)\n",
    "    \n",
    "    filenames   = tf.random.shuffle(filenames)\n",
    "    all_labs    = [get_label(y).numpy().decode() for y in filenames]\n",
    "    filename_df = pd.DataFrame({'name': filenames.numpy(),\n",
    "                                'label': all_labs})\n",
    "    \n",
    "    train, rest_df = train_test_split(filename_df, test_size=0.2, stratify=filename_df[['label']])\n",
    "    val, test      = train_test_split(rest_df, test_size=0.5, stratify = rest_df[['label']])\n",
    "    \n",
    "    train_files = tf.random.shuffle(train['name'])\n",
    "    val_files   = tf.random.shuffle(val['name'])\n",
    "    test_files  = tf.random.shuffle(test['name'])\n",
    "\n",
    "    def concat_xy(ds):\n",
    "            x_tmp  = [x for x,_ in ds]\n",
    "            x_tmp  = tf.stack(x_tmp)\n",
    "            xs_tmp = tf.unstack(x_tmp, axis=-1)\n",
    "            xs_tmp = [tf.expand_dims(x_ind, axis=-1) for x_ind in xs_tmp]\n",
    "            y      = np.array([y for _,y in ds])\n",
    "            return xs_tmp, y\n",
    "    \n",
    "    print('Getting data')\n",
    "    choices  = ['Mod']\n",
    "    train_ds = preprocess_dataset(train_files, choices, categories, req_width=750, resize = 4, spec_norm = True)\n",
    "    val_ds   = preprocess_dataset(val_files,   choices, categories, req_width=750, resize = 4, spec_norm = True)\n",
    "    test_ds  = preprocess_dataset(test_files,  choices, categories, req_width=750, resize = 4, spec_norm = True)\n",
    "    \n",
    "    train_ds_vgg = preprocess_dataset(train_files, choices, categories, req_width=750, single_to_rgb = True, resize = 4, spec_norm = True)\n",
    "    val_ds_vgg   = preprocess_dataset(val_files,   choices, categories, req_width=750, single_to_rgb = True, resize = 4, spec_norm = True)\n",
    "    test_ds_vgg  = preprocess_dataset(test_files,  choices, categories, req_width=750, single_to_rgb = True, resize = 4, spec_norm = True)\n",
    "    \n",
    "    X_train_vgg = np.array([x for x,y in train_ds_vgg])\n",
    "    X_val_vgg   = np.array([x for x,y in val_ds_vgg])\n",
    "    X_test_vgg  = np.array([x for x,y in test_ds_vgg])\n",
    "    \n",
    "    choices = ['Mod', 'AbsRe', 'AbsIm'] #['Mod','AbsRe', 'AbsIm', 'LogMod', 'Ang']\n",
    "    train_ds_mult = preprocess_dataset(train_files, choices, categories, req_width=750, resize = 4, spec_norm = True)\n",
    "    val_ds_mult   = preprocess_dataset(val_files,   choices, categories, req_width=750, resize = 4, spec_norm = True)\n",
    "    test_ds_mult  = preprocess_dataset(test_files,  choices, categories, req_width=750, resize = 4, spec_norm = True)\n",
    "    \n",
    "    X_train_mult, y_train = concat_xy(train_ds_mult)\n",
    "    X_val_mult,   y_val   = concat_xy(val_ds_mult)\n",
    "    X_test_mult,  y_test  = concat_xy(test_ds_mult)\n",
    "    \n",
    "    num_channels = len(choices)\n",
    "    nc = num_channels\n",
    "    \n",
    "    train_ds_mult_vgg = preprocess_dataset(train_files, choices, categories, req_width=750, single_to_rgb = True, resize = 4, spec_norm = True)\n",
    "    val_ds_mult_vgg   = preprocess_dataset(val_files,   choices, categories, req_width=750, single_to_rgb = True, resize = 4, spec_norm = True)\n",
    "    test_ds_mult_vgg  = preprocess_dataset(test_files,  choices, categories, req_width=750, single_to_rgb = True, resize = 4, spec_norm = True)\n",
    "    X_train_mult_vgg, _ = concat_xy(train_ds_mult_vgg)\n",
    "    X_val_mult_vgg,   _ = concat_xy(val_ds_mult_vgg)\n",
    "    X_test_mult_vgg,  _ = concat_xy(test_ds_mult_vgg)\n",
    "    \n",
    "    X_train_mult_vgg = np.array(X_train_mult_vgg)\n",
    "    X_val_mult_vgg   = np.array(X_val_mult_vgg)\n",
    "    X_test_mult_vgg  = np.array(X_test_mult_vgg)\n",
    "    \n",
    "    X_train_mult_vgg = [tf.concat(X_train_mult_vgg[[idx, idx+nc, idx+2*nc]], axis=-1) for idx in range(nc)]\n",
    "    X_val_mult_vgg   = [tf.concat(X_val_mult_vgg[[idx, idx+nc, idx+2*nc]],   axis=-1) for idx in range(nc)]\n",
    "    X_test_mult_vgg  = [tf.concat(X_test_mult_vgg[[idx, idx+nc, idx+2*nc]],  axis=-1) for idx in range(nc)]\n",
    "    \n",
    "    X_train_mult_vgg = [np.rollaxis(np.squeeze(xt), 0, 4) for xt in X_train_mult_vgg]\n",
    "    X_val_mult_vgg   = [np.rollaxis(np.squeeze(xt), 0, 4) for xt in X_val_mult_vgg]\n",
    "    X_test_mult_vgg  = [np.rollaxis(np.squeeze(xt), 0, 4) for xt in X_test_mult_vgg]\n",
    "\n",
    "    print(\"Done\")\n",
    "    \n",
    "    \n",
    "    concat_shape     = X_train_mult[0].shape[1:]\n",
    "    vgg_concat_shape = X_train_mult_vgg[0].shape[1:]\n",
    "    \n",
    "    for spec, _ in train_ds.take(1):\n",
    "        input_shape = spec.shape\n",
    "    for spec, _ in train_ds_vgg.take(1):\n",
    "        input_shape_vgg = spec.shape\n",
    "        #print(tf.math.reduce_std(spec[:,:,0]))\n",
    "        #print(tf.math.reduce_std(spec[:,:,1]))\n",
    "        #print(tf.math.reduce_std(spec[:,:,2]))\n",
    "        \n",
    "    train_ds = train_ds.batch(batch_size)\n",
    "    val_ds   = val_ds.batch(batch_size)\n",
    "    test_ds  = test_ds.batch(batch_size)\n",
    "    train_ds = train_ds.cache().prefetch(AUTOTUNE)\n",
    "    val_ds   = val_ds.cache().prefetch(AUTOTUNE)\n",
    "    test_ds  = test_ds.cache().prefetch(AUTOTUNE)\n",
    "    \n",
    "    if data_dir.startswith(\"C:\"):\n",
    "        sv_dir = '_'.join(data_dir.split(os.path.sep)[1:-2])\n",
    "    else:\n",
    "        sv_dir = data_dir\n",
    "    filename_idx = datetime.now().strftime(\"%Y%m%d-%H%M%S\").replace('-', '_')+'_'+sv_dir.replace('/','_')+'_'+str(index)\n",
    "    results_folder = 'results'\n",
    "    if not os.path.isdir(results_folder):\n",
    "        os.mkdir(results_folder)\n",
    "    \n",
    "    train.to_csv(results_folder+'/'+filename_idx+'_filenames_train.csv')\n",
    "    val.to_csv(results_folder+'/'+filename_idx+'_filenames_val.csv')\n",
    "    test.to_csv(results_folder+'/'+filename_idx+'_filenames_test.csv')\n",
    "    #np.save('results/'+filename_idx+'_filenames.npy', filenames.numpy())\n",
    "    \n",
    "    #this will save the model performing best on val accuracy\n",
    "    def best_model_cp():\n",
    "        checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "            \"best_model\",\n",
    "            monitor = \"val_accuracy\",\n",
    "            mode    = \"max\",\n",
    "            save_best_only = True,\n",
    "            save_weights_only = True)\n",
    "        return checkpoint\n",
    "    \n",
    "    ## Load and run models\n",
    "    \n",
    "    if vgg19 or vgg19_concat:\n",
    "        vgg_model = VGG19(weights='imagenet', include_top=False, input_shape=input_shape_vgg)\n",
    "    #VGG19\n",
    "    if vgg19:\n",
    "        print(\"VGG19\")\n",
    "        tmp_vgg_trainX = vgg_model.predict(X_train_vgg)\n",
    "        tmp_vgg_valX   = vgg_model.predict(X_val_vgg)\n",
    "        tmp_vgg_testX  = vgg_model.predict(X_test_vgg)\n",
    "        model = preload_vgg19(tmp_vgg_trainX.shape[1:])\n",
    "        model_name   = 'vgg19'\n",
    "        filename_run = filename_idx+'_'+model_name\n",
    "        print(model.summary())\n",
    "        history = model.fit(tmp_vgg_trainX, y_train,\n",
    "                            validation_data = (tmp_vgg_valX, y_val),\n",
    "                            callbacks       = [best_model_cp()],\n",
    "                            epochs          = EPOCHS,\n",
    "                            verbose         = 1)\n",
    "\n",
    "        pd.DataFrame(history.history).to_csv(results_folder+'/'+filename_run+'_model_history.csv')\n",
    "\n",
    "        model.load_weights(\"best_model\")\n",
    "\n",
    "        save_results(model, tmp_vgg_testX, y_test, model_name, filename_run, index)\n",
    "    \n",
    "    \n",
    "    #VGG19_concat\n",
    "    if vgg19_concat:\n",
    "        print(\"VGG19_concat\")\n",
    "        tmp_X_train_mult_vgg = [vgg_model.predict(xt) for xt in X_train_mult_vgg]\n",
    "        tmp_X_val_mult_vgg   = [vgg_model.predict(xt) for xt in X_val_mult_vgg]\n",
    "        tmp_X_test_mult_vgg  = [vgg_model.predict(xt) for xt in X_test_mult_vgg]\n",
    "        #model    = load_vgg19_concat(vgg_concat_shape, num_channels)\n",
    "        model_name   = 'vgg19_concat'\n",
    "        filename_run = filename_idx+'_'+model_name\n",
    "        model = preload_vgg19_concat(tmp_X_train_mult_vgg[0].shape[1:], num_channels)\n",
    "        print(model.summary())\n",
    "        history = model.fit(tmp_X_train_mult_vgg, y_train,\n",
    "                            validation_data = (tmp_X_val_mult_vgg, y_val),\n",
    "                            callbacks       = [best_model_cp()],\n",
    "                            epochs          = EPOCHS,\n",
    "                            verbose         = 1)\n",
    "\n",
    "        pd.DataFrame(history.history).to_csv(results_folder+'/'+filename_run+'_model_history.csv')\n",
    "\n",
    "        model.load_weights(\"best_model\")\n",
    "\n",
    "        save_results(model, tmp_X_test_mult_vgg, y_test, model_name, filename_run, index)\n",
    "\n",
    "\n",
    "    #ResNet50\n",
    "    if resnet50:\n",
    "        print(\"ResNet50\")\n",
    "        model = load_resnet50(input_shape_vgg)\n",
    "        model_name   = 'resnet50'\n",
    "        filename_run = filename_idx+'_'+model_name\n",
    "\n",
    "        history = model.fit(train_ds,\n",
    "                            validation_data = val_ds,\n",
    "                            callbacks       = [best_model_cp()],\n",
    "                            epochs          = EPOCHS,\n",
    "                            verbose         = 1)\n",
    "\n",
    "        pd.DataFrame(history.history).to_csv(results_folder+'/'+filename_run+'_model_history.csv')\n",
    "\n",
    "        model.load_weights(\"best_model\")\n",
    "\n",
    "        save_results(model, test_ds, y_test, model_name, filename_run, index)\n",
    "    \n",
    "    #ResNet50_concat\n",
    "    if resnet50_concat:\n",
    "        print(\"ResNet50_concat\")\n",
    "        model    = load_resnet50_concat(vgg_concat_shape, num_channels)\n",
    "        model_name   = 'resnet50_concat'\n",
    "        filename_run = filename_idx+'_'+model_name\n",
    "\n",
    "        history = model.fit(X_train_vgg, y_train,\n",
    "                            validation_data = (X_val_vgg, y_val),\n",
    "                            callbacks       = [best_model_cp()],\n",
    "                            epochs          = EPOCHS,\n",
    "                            verbose         = 1)\n",
    "\n",
    "        pd.DataFrame(history.history).to_csv(results_folder+'/'+filename_run+'_model_history.csv')\n",
    "\n",
    "        model.load_weights(\"best_model\")\n",
    "\n",
    "        save_results(model, X_test_vgg, y_test, model_name, filename_run, index)\n",
    "\n",
    "    #small_cnn\n",
    "    if smallcnn:\n",
    "        print(\"Small CNN\")\n",
    "        model  = main_cnn(input_shape, num_classes)\n",
    "        model_name   = 'smallcnn'\n",
    "        filename_run = filename_idx+'_'+model_name\n",
    "\n",
    "        history = model.fit(train_ds,\n",
    "                            validation_data = val_ds,\n",
    "                            callbacks       = [best_model_cp()],\n",
    "                            epochs          = EPOCHS,\n",
    "                            verbose         = 1)\n",
    "\n",
    "        pd.DataFrame(history.history).to_csv(results_folder+'/'+filename_run+'_model_history.csv')\n",
    "\n",
    "        model.load_weights(\"best_model\")\n",
    "\n",
    "        save_results(model, test_ds, y_test, model_name, filename_run, index)\n",
    "    \n",
    "    #concat\n",
    "    if concat:\n",
    "        print(\"Concat\")\n",
    "        model        = concat_model(concat_shape, num_channels, num_classes)\n",
    "        model_name   = 'concat'\n",
    "        filename_run = filename_idx+'_'+model_name\n",
    "\n",
    "        history = model.fit(X_train_mult, y_train,\n",
    "                            validation_data = (X_val_mult, y_val),\n",
    "                            callbacks       = [best_model_cp()],\n",
    "                            epochs          = EPOCHS,\n",
    "                            batch_size      = batch_size,\n",
    "                            verbose         = 1)\n",
    "\n",
    "        pd.DataFrame(history.history).to_csv(results_folder+'/'+filename_run+'_model_history.csv')\n",
    "\n",
    "        model.load_weights(\"best_model\")\n",
    "\n",
    "        save_results(model, X_test_mult, y_test, model_name, filename_run, index)\n",
    "\n",
    "    #concat2\n",
    "    if concat2:\n",
    "        print(\"Concat2\")\n",
    "        model     = concat_model2(concat_shape, num_channels, num_classes)\n",
    "        model_name   = 'concat2'\n",
    "        filename_run = filename_idx+'_'+model_name\n",
    "\n",
    "        history = model.fit(X_train_mult, y_train,\n",
    "                            validation_data = (X_val_mult, y_val),\n",
    "                            callbacks       = [best_model_cp()],\n",
    "                            epochs          = EPOCHS,\n",
    "                            batch_size      = batch_size,\n",
    "                            verbose         = 1)\n",
    "\n",
    "        pd.DataFrame(history.history).to_csv(results_folder+'/'+filename_run+'_model_history.csv')\n",
    "\n",
    "        model.load_weights(\"best_model\")\n",
    "\n",
    "        save_results(model, X_test_mult, y_test, model_name, filename_run, index)\n",
    "    \n",
    "    #concat3\n",
    "    if concat3:\n",
    "        print(\"Concat3\")\n",
    "        model     = concat_model3(concat_shape, num_channels, num_classes)\n",
    "        model_name   = 'concat3'\n",
    "        filename_run = filename_idx+'_'+model_name\n",
    "\n",
    "        history = model.fit(X_train_mult, y_train,\n",
    "                            validation_data = (X_val_mult, y_val),\n",
    "                            callbacks       = [best_model_cp()],\n",
    "                            epochs          = EPOCHS,\n",
    "                            batch_size      = batch_size,\n",
    "                            verbose         = 1)\n",
    "\n",
    "        pd.DataFrame(history.history).to_csv(results_folder+'/'+filename_run+'_model_history.csv')\n",
    "\n",
    "        model.load_weights(\"best_model\")\n",
    "\n",
    "        save_results(model, X_test_mult, y_test, model_name, filename_run, index)\n",
    "    \n",
    "    #concat4\n",
    "    if concat4:\n",
    "        print(\"Concat4\")\n",
    "        model     = concat_model4(concat_shape, num_channels, num_classes)\n",
    "        model_name   = 'concat4'\n",
    "        filename_run = filename_idx+'_'+model_name\n",
    "\n",
    "        history = model.fit(X_train_mult, y_train,\n",
    "                            validation_data = (X_val_mult, y_val),\n",
    "                            callbacks       = [best_model_cp()],\n",
    "                            epochs          = EPOCHS,\n",
    "                            batch_size      = batch_size,\n",
    "                            verbose         = 1)\n",
    "\n",
    "        pd.DataFrame(history.history).to_csv(results_folder+'/'+filename_run+'_model_history.csv')\n",
    "\n",
    "        model.load_weights(\"best_model\")\n",
    "\n",
    "        save_results(model, X_test_mult, y_test, model_name, filename_run, index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9ce69b",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9447e6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#audio_df = pd.DataFrame({'fname': [], 'sr': [], 'len': []})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "49700df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for file_path in filenames:\n",
    "#    audio_binary  = tf.io.read_file(file_path)\n",
    "#    waveform, sr  = decode_audio(audio_binary)\n",
    "#    sr = sr.numpy()\n",
    "#    if len(waveform)/sr < 0.23:\n",
    "#        os.remove(file_path.numpy().decode())\n",
    "#        continue\n",
    "#    row = pd.DataFrame({'fname': [file_path], 'sr': [sr], 'len': [len(waveform)/sr]})\n",
    "#    audio_df = pd.concat([audio_df, row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "73947c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#audio_binary  = tf.io.read_file(filenames[0])\n",
    "#waveform, sr  = decode_audio(audio_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f23056f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#audio_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a666e92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#audio_df.iloc[8028]['fname'].numpy().decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0ca603b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#audio_df[audio_df['len']<0.23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9db0fff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7690"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b1524e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6a65dbee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:  1\n",
      "Getting data\n",
      "Done\n",
      "VGG19\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 47104)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               12058880  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 12,075,458\n",
      "Trainable params: 12,075,458\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "25/25 [==============================] - 1s 36ms/step - loss: 0.7045 - accuracy: 0.7013 - val_loss: 0.4929 - val_accuracy: 0.8000\n",
      "Epoch 2/50\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.5390 - accuracy: 0.7650 - val_loss: 0.4526 - val_accuracy: 0.8500\n",
      "Epoch 3/50\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 0.5071 - accuracy: 0.7887 - val_loss: 0.4263 - val_accuracy: 0.8300\n",
      "Epoch 4/50\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.4721 - accuracy: 0.7887 - val_loss: 0.4147 - val_accuracy: 0.8300\n",
      "Epoch 5/50\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.4699 - accuracy: 0.7962 - val_loss: 0.4023 - val_accuracy: 0.8700\n",
      "Epoch 6/50\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.4507 - accuracy: 0.8188 - val_loss: 0.4038 - val_accuracy: 0.8500\n",
      "Epoch 7/50\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.4250 - accuracy: 0.8138 - val_loss: 0.3862 - val_accuracy: 0.8700\n",
      "Epoch 8/50\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.3873 - accuracy: 0.8388 - val_loss: 0.3836 - val_accuracy: 0.8900\n",
      "Epoch 9/50\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 0.4166 - accuracy: 0.8125 - val_loss: 0.3777 - val_accuracy: 0.8600\n",
      "Epoch 10/50\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.4018 - accuracy: 0.8238 - val_loss: 0.3894 - val_accuracy: 0.8700\n",
      "Epoch 11/50\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.3804 - accuracy: 0.8475 - val_loss: 0.3814 - val_accuracy: 0.8500\n",
      "Epoch 12/50\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.3743 - accuracy: 0.8363 - val_loss: 0.3665 - val_accuracy: 0.8800\n",
      "Epoch 13/50\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.3529 - accuracy: 0.8450 - val_loss: 0.3647 - val_accuracy: 0.8700\n",
      "Epoch 14/50\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.3400 - accuracy: 0.8375 - val_loss: 0.3777 - val_accuracy: 0.8600\n",
      "Epoch 15/50\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.3431 - accuracy: 0.8562 - val_loss: 0.4012 - val_accuracy: 0.8300\n",
      "Epoch 16/50\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.3384 - accuracy: 0.8550 - val_loss: 0.3605 - val_accuracy: 0.8700\n",
      "Epoch 17/50\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.3302 - accuracy: 0.8550 - val_loss: 0.3756 - val_accuracy: 0.8400\n",
      "Epoch 18/50\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.3076 - accuracy: 0.8662 - val_loss: 0.3530 - val_accuracy: 0.8700\n",
      "Epoch 19/50\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.3134 - accuracy: 0.8700 - val_loss: 0.3597 - val_accuracy: 0.8700\n",
      "Epoch 20/50\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.2896 - accuracy: 0.8775 - val_loss: 0.3739 - val_accuracy: 0.8700\n",
      "Epoch 21/50\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.2863 - accuracy: 0.8750 - val_loss: 0.3836 - val_accuracy: 0.8500\n",
      "Epoch 22/50\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.2824 - accuracy: 0.8800 - val_loss: 0.3696 - val_accuracy: 0.8800\n",
      "Epoch 23/50\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.2949 - accuracy: 0.8637 - val_loss: 0.3582 - val_accuracy: 0.8800\n",
      "Epoch 24/50\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.2947 - accuracy: 0.8775 - val_loss: 0.3446 - val_accuracy: 0.8800\n",
      "Epoch 25/50\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.2918 - accuracy: 0.8725 - val_loss: 0.3843 - val_accuracy: 0.8700\n",
      "Epoch 26/50\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.2833 - accuracy: 0.8725 - val_loss: 0.3706 - val_accuracy: 0.8700\n",
      "Epoch 27/50\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.2486 - accuracy: 0.8863 - val_loss: 0.3577 - val_accuracy: 0.8600\n",
      "Epoch 28/50\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.2604 - accuracy: 0.8950 - val_loss: 0.3542 - val_accuracy: 0.8800\n",
      "Epoch 29/50\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.2602 - accuracy: 0.8925 - val_loss: 0.3824 - val_accuracy: 0.8500\n",
      "Epoch 30/50\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.2583 - accuracy: 0.8975 - val_loss: 0.3478 - val_accuracy: 0.8900\n",
      "Epoch 31/50\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.2311 - accuracy: 0.8925 - val_loss: 0.4012 - val_accuracy: 0.8400\n",
      "Epoch 32/50\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.2431 - accuracy: 0.9000 - val_loss: 0.3701 - val_accuracy: 0.8900\n",
      "Epoch 33/50\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.2208 - accuracy: 0.9100 - val_loss: 0.3790 - val_accuracy: 0.8800\n",
      "Epoch 34/50\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.2291 - accuracy: 0.9050 - val_loss: 0.3681 - val_accuracy: 0.8700\n",
      "Epoch 35/50\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.2031 - accuracy: 0.9112 - val_loss: 0.3869 - val_accuracy: 0.8500\n",
      "Epoch 36/50\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.2252 - accuracy: 0.9038 - val_loss: 0.3976 - val_accuracy: 0.8800\n",
      "Epoch 37/50\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.2191 - accuracy: 0.9075 - val_loss: 0.3795 - val_accuracy: 0.8400\n",
      "Epoch 38/50\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.2166 - accuracy: 0.9125 - val_loss: 0.3857 - val_accuracy: 0.8800\n",
      "Epoch 39/50\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.2096 - accuracy: 0.9162 - val_loss: 0.3960 - val_accuracy: 0.8700\n",
      "Epoch 40/50\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1967 - accuracy: 0.9200 - val_loss: 0.3893 - val_accuracy: 0.8700\n",
      "Epoch 41/50\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.2061 - accuracy: 0.9112 - val_loss: 0.3962 - val_accuracy: 0.8700\n",
      "Epoch 42/50\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1956 - accuracy: 0.9200 - val_loss: 0.4005 - val_accuracy: 0.8700\n",
      "Epoch 43/50\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1868 - accuracy: 0.9250 - val_loss: 0.3977 - val_accuracy: 0.8700\n",
      "Epoch 44/50\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.2073 - accuracy: 0.9200 - val_loss: 0.3876 - val_accuracy: 0.8600\n",
      "Epoch 45/50\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1820 - accuracy: 0.9175 - val_loss: 0.3897 - val_accuracy: 0.8900\n",
      "Epoch 46/50\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1623 - accuracy: 0.9450 - val_loss: 0.4338 - val_accuracy: 0.8500\n",
      "Epoch 47/50\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1970 - accuracy: 0.9087 - val_loss: 0.3479 - val_accuracy: 0.8700\n",
      "Epoch 48/50\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1862 - accuracy: 0.9250 - val_loss: 0.4371 - val_accuracy: 0.8700\n",
      "Epoch 49/50\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1848 - accuracy: 0.9225 - val_loss: 0.3985 - val_accuracy: 0.8700\n",
      "Epoch 50/50\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1574 - accuracy: 0.9388 - val_loss: 0.4452 - val_accuracy: 0.8600\n",
      "VGG19_concat\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 4, 23, 512)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 4, 23, 512)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            [(None, 4, 23, 512)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            [(None, 4, 23, 512)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 4, 23, 2048)  0           input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "                                                                 input_5[0][0]                    \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 188416)       0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 256)          48234752    flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256)          0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 64)           16448       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 2)            130         dense_4[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 48,251,330\n",
      "Trainable params: 48,251,330\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 4s 133ms/step - loss: 1.7936 - accuracy: 0.6725 - val_loss: 0.7551 - val_accuracy: 0.7700\n",
      "Epoch 2/50\n",
      "25/25 [==============================] - 3s 126ms/step - loss: 1.1398 - accuracy: 0.6775 - val_loss: 0.4479 - val_accuracy: 0.8300\n",
      "Epoch 3/50\n",
      "25/25 [==============================] - 3s 126ms/step - loss: 0.6467 - accuracy: 0.7538 - val_loss: 0.6765 - val_accuracy: 0.5300\n",
      "Epoch 4/50\n",
      "25/25 [==============================] - 3s 128ms/step - loss: 0.5266 - accuracy: 0.7650 - val_loss: 0.4349 - val_accuracy: 0.8200\n",
      "Epoch 5/50\n",
      "25/25 [==============================] - 3s 128ms/step - loss: 0.4735 - accuracy: 0.7925 - val_loss: 0.4262 - val_accuracy: 0.8600\n",
      "Epoch 6/50\n",
      "25/25 [==============================] - 3s 125ms/step - loss: 0.4564 - accuracy: 0.7987 - val_loss: 0.4454 - val_accuracy: 0.8300\n",
      "Epoch 7/50\n",
      "25/25 [==============================] - 3s 132ms/step - loss: 0.4534 - accuracy: 0.8062 - val_loss: 0.4205 - val_accuracy: 0.8000\n",
      "Epoch 8/50\n",
      "25/25 [==============================] - 3s 128ms/step - loss: 0.4420 - accuracy: 0.8000 - val_loss: 0.4197 - val_accuracy: 0.8700\n",
      "Epoch 9/50\n",
      "25/25 [==============================] - 3s 124ms/step - loss: 0.4712 - accuracy: 0.7962 - val_loss: 0.3919 - val_accuracy: 0.8300\n",
      "Epoch 10/50\n",
      "25/25 [==============================] - 3s 122ms/step - loss: 0.4192 - accuracy: 0.8275 - val_loss: 0.3839 - val_accuracy: 0.8600\n",
      "Epoch 11/50\n",
      "25/25 [==============================] - 3s 123ms/step - loss: 0.4112 - accuracy: 0.8288 - val_loss: 0.4406 - val_accuracy: 0.8000\n",
      "Epoch 12/50\n",
      "25/25 [==============================] - 3s 122ms/step - loss: 0.4250 - accuracy: 0.8150 - val_loss: 0.3990 - val_accuracy: 0.8500\n",
      "Epoch 13/50\n",
      "25/25 [==============================] - 3s 123ms/step - loss: 0.4157 - accuracy: 0.8288 - val_loss: 0.4649 - val_accuracy: 0.8000\n",
      "Epoch 14/50\n",
      "25/25 [==============================] - 3s 122ms/step - loss: 0.4102 - accuracy: 0.7975 - val_loss: 0.4399 - val_accuracy: 0.7800\n",
      "Epoch 15/50\n",
      "25/25 [==============================] - 3s 125ms/step - loss: 0.4157 - accuracy: 0.8075 - val_loss: 0.4196 - val_accuracy: 0.8600\n",
      "Epoch 16/50\n",
      "25/25 [==============================] - 3s 123ms/step - loss: 0.4073 - accuracy: 0.8138 - val_loss: 0.4198 - val_accuracy: 0.8100\n",
      "Epoch 17/50\n",
      "25/25 [==============================] - 3s 127ms/step - loss: 0.4094 - accuracy: 0.8138 - val_loss: 0.3997 - val_accuracy: 0.8500\n",
      "Epoch 18/50\n",
      "25/25 [==============================] - 3s 125ms/step - loss: 0.3766 - accuracy: 0.8238 - val_loss: 0.4123 - val_accuracy: 0.8600\n",
      "Epoch 19/50\n",
      "25/25 [==============================] - 3s 130ms/step - loss: 0.3921 - accuracy: 0.8087 - val_loss: 0.4080 - val_accuracy: 0.8400\n",
      "Epoch 20/50\n",
      "25/25 [==============================] - 3s 125ms/step - loss: 0.3504 - accuracy: 0.8225 - val_loss: 0.4264 - val_accuracy: 0.8000\n",
      "Epoch 21/50\n",
      "25/25 [==============================] - 3s 124ms/step - loss: 0.3889 - accuracy: 0.7738 - val_loss: 0.4377 - val_accuracy: 0.7700\n",
      "Epoch 22/50\n",
      "25/25 [==============================] - 3s 125ms/step - loss: 0.3824 - accuracy: 0.7713 - val_loss: 0.4330 - val_accuracy: 0.7700\n",
      "Epoch 23/50\n",
      "25/25 [==============================] - 3s 123ms/step - loss: 0.4195 - accuracy: 0.7713 - val_loss: 0.4677 - val_accuracy: 0.7700\n",
      "Epoch 24/50\n",
      "25/25 [==============================] - 3s 124ms/step - loss: 0.4059 - accuracy: 0.7713 - val_loss: 0.4462 - val_accuracy: 0.7700\n",
      "Epoch 25/50\n",
      "25/25 [==============================] - 3s 127ms/step - loss: 0.3814 - accuracy: 0.7713 - val_loss: 0.4273 - val_accuracy: 0.7700\n",
      "Epoch 26/50\n",
      "25/25 [==============================] - 3s 122ms/step - loss: 0.3700 - accuracy: 0.7713 - val_loss: 0.4228 - val_accuracy: 0.7700\n",
      "Epoch 27/50\n",
      "25/25 [==============================] - 3s 123ms/step - loss: 0.4001 - accuracy: 0.7713 - val_loss: 0.4327 - val_accuracy: 0.7700\n",
      "Epoch 28/50\n",
      "25/25 [==============================] - 3s 124ms/step - loss: 0.3951 - accuracy: 0.7713 - val_loss: 0.4363 - val_accuracy: 0.7700\n",
      "Epoch 29/50\n",
      "25/25 [==============================] - 3s 123ms/step - loss: 0.3663 - accuracy: 0.7713 - val_loss: 0.4262 - val_accuracy: 0.7700\n",
      "Epoch 30/50\n",
      "25/25 [==============================] - 3s 124ms/step - loss: 0.3626 - accuracy: 0.7713 - val_loss: 0.4356 - val_accuracy: 0.7700\n",
      "Epoch 31/50\n",
      "25/25 [==============================] - 3s 124ms/step - loss: 0.3405 - accuracy: 0.7713 - val_loss: 0.4378 - val_accuracy: 0.7700\n",
      "Epoch 32/50\n",
      "25/25 [==============================] - 3s 124ms/step - loss: 0.3354 - accuracy: 0.7713 - val_loss: 0.4258 - val_accuracy: 0.7700\n",
      "Epoch 33/50\n",
      "25/25 [==============================] - 3s 123ms/step - loss: 0.3397 - accuracy: 0.7713 - val_loss: 0.4313 - val_accuracy: 0.7700\n",
      "Epoch 34/50\n",
      "25/25 [==============================] - 3s 128ms/step - loss: 0.3217 - accuracy: 0.7688 - val_loss: 0.4274 - val_accuracy: 0.8200\n",
      "Epoch 35/50\n",
      "25/25 [==============================] - 3s 124ms/step - loss: 0.3218 - accuracy: 0.8325 - val_loss: 0.4434 - val_accuracy: 0.8600\n",
      "Epoch 36/50\n",
      "25/25 [==============================] - 3s 123ms/step - loss: 0.3050 - accuracy: 0.8575 - val_loss: 0.4519 - val_accuracy: 0.8400\n",
      "Epoch 37/50\n",
      "25/25 [==============================] - 3s 124ms/step - loss: 0.3051 - accuracy: 0.8662 - val_loss: 0.4542 - val_accuracy: 0.8100\n",
      "Epoch 38/50\n",
      "25/25 [==============================] - 3s 124ms/step - loss: 0.2884 - accuracy: 0.8813 - val_loss: 0.4494 - val_accuracy: 0.8200\n",
      "Epoch 39/50\n",
      "25/25 [==============================] - 3s 124ms/step - loss: 0.2931 - accuracy: 0.8725 - val_loss: 0.4553 - val_accuracy: 0.8200\n",
      "Epoch 40/50\n",
      "25/25 [==============================] - 3s 124ms/step - loss: 0.3151 - accuracy: 0.8475 - val_loss: 0.4598 - val_accuracy: 0.8100\n",
      "Epoch 41/50\n",
      "25/25 [==============================] - 3s 125ms/step - loss: 0.3422 - accuracy: 0.8175 - val_loss: 0.4209 - val_accuracy: 0.8200\n",
      "Epoch 42/50\n",
      "25/25 [==============================] - 3s 128ms/step - loss: 0.3908 - accuracy: 0.7312 - val_loss: 0.4431 - val_accuracy: 0.8500\n",
      "Epoch 43/50\n",
      "25/25 [==============================] - 3s 125ms/step - loss: 0.3465 - accuracy: 0.7925 - val_loss: 0.4331 - val_accuracy: 0.8400\n",
      "Epoch 44/50\n",
      "25/25 [==============================] - 3s 130ms/step - loss: 0.3219 - accuracy: 0.8200 - val_loss: 0.4395 - val_accuracy: 0.8400\n",
      "Epoch 45/50\n",
      "25/25 [==============================] - 3s 129ms/step - loss: 0.3134 - accuracy: 0.8300 - val_loss: 0.4393 - val_accuracy: 0.8200\n",
      "Epoch 46/50\n",
      "25/25 [==============================] - 3s 132ms/step - loss: 0.3246 - accuracy: 0.8037 - val_loss: 0.4676 - val_accuracy: 0.8200\n",
      "Epoch 47/50\n",
      "25/25 [==============================] - 3s 125ms/step - loss: 0.3333 - accuracy: 0.8138 - val_loss: 0.4457 - val_accuracy: 0.8500\n",
      "Epoch 48/50\n",
      "25/25 [==============================] - 3s 126ms/step - loss: 0.3391 - accuracy: 0.8050 - val_loss: 0.5817 - val_accuracy: 0.8100\n",
      "Epoch 49/50\n",
      "25/25 [==============================] - 3s 127ms/step - loss: 0.3436 - accuracy: 0.7912 - val_loss: 0.4382 - val_accuracy: 0.8500\n",
      "Epoch 50/50\n",
      "25/25 [==============================] - 3s 124ms/step - loss: 0.3060 - accuracy: 0.8475 - val_loss: 0.5030 - val_accuracy: 0.8300\n",
      "Time so far: 1873.3587188720703\n",
      "Index:  2\n",
      "Getting data\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-176ee1e17450>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     main_model_run(filenames[:1000], i,\n\u001b[0m\u001b[0;32m      3\u001b[0m                    \u001b[0mvgg19\u001b[0m        \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                    \u001b[0mvgg19_concat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                    \u001b[1;31m#resnet50     = True,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-32-fa52bbd28d5a>\u001b[0m in \u001b[0;36mmain_model_run\u001b[1;34m(filenames, index, vgg19, vgg19_concat, resnet50, resnet50_concat, smallcnn, concat, concat2, concat3, concat4)\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[0mval_ds_mult_vgg\u001b[0m   \u001b[1;33m=\u001b[0m \u001b[0mpreprocess_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_files\u001b[0m\u001b[1;33m,\u001b[0m   \u001b[0mchoices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategories\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq_width\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m750\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msingle_to_rgb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspec_norm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[0mtest_ds_mult_vgg\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mpreprocess_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_files\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mchoices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategories\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq_width\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m750\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msingle_to_rgb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspec_norm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m     \u001b[0mX_train_mult_vgg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconcat_xy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_ds_mult_vgg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m     \u001b[0mX_val_mult_vgg\u001b[0m\u001b[1;33m,\u001b[0m   \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconcat_xy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_ds_mult_vgg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[0mX_test_mult_vgg\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconcat_xy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_ds_mult_vgg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-32-fa52bbd28d5a>\u001b[0m in \u001b[0;36mconcat_xy\u001b[1;34m(ds)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mconcat_xy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m             \u001b[0mx_tmp\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mds\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m             \u001b[0mx_tmp\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_tmp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m             \u001b[0mxs_tmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_tmp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-32-fa52bbd28d5a>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mconcat_xy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m             \u001b[0mx_tmp\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mds\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m             \u001b[0mx_tmp\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_tmp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m             \u001b[0mxs_tmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_tmp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    759\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    760\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 761\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    762\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    763\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    742\u001b[0m     \u001b[1;31m# to communicate that there is no more data to iterate over.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    743\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecution_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSYNC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 744\u001b[1;33m       ret = gen_dataset_ops.iterator_get_next(\n\u001b[0m\u001b[0;32m    745\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    746\u001b[0m           \u001b[0moutput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[1;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[0;32m   2720\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2721\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2722\u001b[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[0;32m   2723\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"IteratorGetNext\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"output_types\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2724\u001b[0m         \"output_shapes\", output_shapes)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(1,5+1):\n",
    "    main_model_run(filenames[:1000], i,\n",
    "                   vgg19        = True,\n",
    "                   vgg19_concat = True\n",
    "                   #resnet50     = True,\n",
    "                   #resnet50_concat = True,\n",
    "                   #smallcnn = True,\n",
    "                   #concat   = True\n",
    "                  )\n",
    "                   #concat2  = True,\n",
    "                   #concat3  = True,\n",
    "                   #concat4  = True)\n",
    "    print(\"Time so far:\", time.time() - tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc963a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "toc = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41b66e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea6ac17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(res_df_t.to_latex(bold_rows = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9fb407",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!zip -r results.zip results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
